{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hp1w7PTW25h3"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g4G4GRX526Bl"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yYTCbgBC3Fl6"
      },
      "outputs": [],
      "source": [
        "!pip install kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "udu1nSjV3KRk"
      },
      "outputs": [],
      "source": [
        "!mkdir -p ~/.kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HP8EQRRz3Mui"
      },
      "outputs": [],
      "source": [
        "!mv kaggle.json ~/.kaggle/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kpcothxk3O6W"
      },
      "outputs": [],
      "source": [
        "!!kaggle competitions download -c deepfake-detection-challenge\n",
        "\n",
        "!unzip deepfake-detection-challenge.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KCBq_Svm5LfF"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "import os\n",
        "import json\n",
        "\n",
        "def filter_and_copy_videos(metadata, source_dir, target_dir, num_real=5, num_fake=5):\n",
        "    # Create target directory if it does not exist\n",
        "    if not os.path.exists(target_dir):\n",
        "        os.makedirs(target_dir)\n",
        "\n",
        "    # Extract real and fake video filenames from metadata\n",
        "    real_videos = [video for video, info in metadata.items() if info['label'] == 'REAL']\n",
        "    fake_videos = [video for video, info in metadata.items() if info['label'] == 'FAKE']\n",
        "\n",
        "    # Select the desired number of videos\n",
        "    selected_real_videos = real_videos[:num_real]\n",
        "    selected_fake_videos = fake_videos[:num_fake]\n",
        "\n",
        "    # Combine selected videos\n",
        "    all_selected_videos = selected_real_videos + selected_fake_videos\n",
        "\n",
        "    # Copy selected videos to the target directory\n",
        "    for video in all_selected_videos:\n",
        "        src = os.path.join(source_dir, video)\n",
        "        dst = os.path.join(target_dir, video)\n",
        "        if os.path.exists(src):\n",
        "            shutil.copy(src, dst)\n",
        "            print(f\"Copied {video} to {target_dir}\")\n",
        "        else:\n",
        "            print(f\"Video not found: {src}\")\n",
        "\n",
        "# Load metadata.json\n",
        "with open('train_sample_videos/metadata.json', 'r') as f:\n",
        "    metadata = json.load(f)\n",
        "\n",
        "# Define directories\n",
        "source_dir = 'train_sample_videos'\n",
        "target_dir = 'selected_videos'\n",
        "\n",
        "# Filter and copy videos\n",
        "filter_and_copy_videos(metadata, source_dir, target_dir)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DhWIdXNg5Pxc"
      },
      "outputs": [],
      "source": [
        "\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "\n",
        "# Define source and target directories\n",
        "source_dir = '/content/selected_videos'  # Update this to your Colab directory\n",
        "target_dir = '/content/drive/MyDrive/10videos'  # Update this to your Google Drive directory\n",
        "\n",
        "# Create the target directory in Google Drive if it doesn't exist\n",
        "os.makedirs(target_dir, exist_ok=True)\n",
        "\n",
        "# Move files from Colab environment to Google Drive\n",
        "for filename in os.listdir(source_dir):\n",
        "    src_path = os.path.join(source_dir, filename)\n",
        "    dst_path = os.path.join(target_dir, filename)\n",
        "    shutil.move(src_path, dst_path)\n",
        "\n",
        "print(\"Files moved to Google Drive successfully.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rn9t8drq8q-g"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import json\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define directories\n",
        "base_dir = '/content/drive/MyDrive/train_sample_videos'\n",
        "source_dir = '/content/selected_videos'\n",
        "selected_real_videos_dir = os.path.join(base_dir, 'selected_real_videos')\n",
        "selected_fake_videos_dir = os.path.join(base_dir, 'selected_fake_videos')\n",
        "\n",
        "# Load metadata.json\n",
        "with open('/content/train_sample_videos/metadata.json', 'r') as f:\n",
        "    metadata = json.load(f)\n",
        "\n",
        "def filter_and_copy_videos(metadata, source_dir, num_real=5, num_fake=5):\n",
        "    # Create target directory if it does not exist\n",
        "    if not os.path.exists(source_dir):\n",
        "        os.makedirs(source_dir)\n",
        "\n",
        "    # Extract real and fake video filenames from metadata\n",
        "    real_videos = [video for video, info in metadata.items() if info['label'] == 'REAL']\n",
        "    fake_videos = [video for video, info in metadata.items() if info['label'] == 'FAKE']\n",
        "\n",
        "    # Select the desired number of videos\n",
        "    selected_real_videos = real_videos[:num_real]\n",
        "    selected_fake_videos = fake_videos[:num_fake]\n",
        "\n",
        "    # Combine selected videos\n",
        "    all_selected_videos = selected_real_videos + selected_fake_videos\n",
        "\n",
        "    # Copy selected videos to the target directory\n",
        "    for video in all_selected_videos:\n",
        "        src = os.path.join('train_sample_videos', video)\n",
        "        dst = os.path.join(source_dir, video)\n",
        "        if os.path.exists(src):\n",
        "            shutil.copy(src, dst)\n",
        "            print(f\"Copied {video} to {source_dir}\")\n",
        "        else:\n",
        "            print(f\"Video not found: {src}\")\n",
        "\n",
        "# Filter and copy videos\n",
        "filter_and_copy_videos(metadata, source_dir)\n",
        "\n",
        "# Create directories in Google Drive for real and fake videos\n",
        "os.makedirs(selected_real_videos_dir, exist_ok=True)\n",
        "os.makedirs(selected_fake_videos_dir, exist_ok=True)\n",
        "\n",
        "# Separate the copied videos into real and fake directories\n",
        "for filename in os.listdir(source_dir):\n",
        "    src_path = os.path.join(source_dir, filename)\n",
        "    if filename in metadata:\n",
        "        label = metadata[filename]['label']\n",
        "        if label == 'REAL':\n",
        "            dst_path = os.path.join(selected_real_videos_dir, filename)\n",
        "        elif label == 'FAKE':\n",
        "            dst_path = os.path.join(selected_fake_videos_dir, filename)\n",
        "        else:\n",
        "            print(f\"Unknown label for {filename}: {label}\")\n",
        "            continue\n",
        "        shutil.move(src_path, dst_path)\n",
        "        print(f\"Moved {filename} to {dst_path}\")\n",
        "\n",
        "print(\"Videos separated and moved to Google Drive successfully.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pCcF-zVR9LSv"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "\n",
        "# Define directories for frames\n",
        "frames_real_videos_dir = os.path.join(base_dir, 'frames_real_videos')\n",
        "frames_fake_videos_dir = os.path.join(base_dir, 'frames_fake_videos')\n",
        "\n",
        "# Create directories for frames in Google Drive\n",
        "os.makedirs(frames_real_videos_dir, exist_ok=True)\n",
        "os.makedirs(frames_fake_videos_dir, exist_ok=True)\n",
        "\n",
        "def extract_frames(video_path, frames_output_dir):\n",
        "    \"\"\"\n",
        "    Extracts frames from a video and saves them to the specified directory.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        vidcap = cv2.VideoCapture(video_path)\n",
        "        if not vidcap.isOpened():\n",
        "            print(f\"Error: Unable to open video file {video_path}\")\n",
        "            return\n",
        "        count = 0\n",
        "        success, image = vidcap.read()\n",
        "        while success:\n",
        "            frame_filename = os.path.join(frames_output_dir, f\"frame_{count:04d}.jpg\")\n",
        "            cv2.imwrite(frame_filename, image)  # Save frame as JPEG file\n",
        "            success, image = vidcap.read()\n",
        "            count += 1\n",
        "        vidcap.release()\n",
        "        print(f\"Frames extracted and saved to {frames_output_dir}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error extracting frames from {video_path}: {e}\")\n",
        "\n",
        "# Extract frames from real videos\n",
        "for filename in os.listdir(selected_real_videos_dir):\n",
        "    video_path = os.path.join(selected_real_videos_dir, filename)\n",
        "    frames_output_dir = os.path.join(frames_real_videos_dir, os.path.splitext(filename)[0])\n",
        "    os.makedirs(frames_output_dir, exist_ok=True)  # Create directory for each video's frames\n",
        "    extract_frames(video_path, frames_output_dir)\n",
        "\n",
        "# Extract frames from fake videos\n",
        "for filename in os.listdir(selected_fake_videos_dir):\n",
        "    video_path = os.path.join(selected_fake_videos_dir, filename)\n",
        "    frames_output_dir = os.path.join(frames_fake_videos_dir, os.path.splitext(filename)[0])\n",
        "    os.makedirs(frames_output_dir, exist_ok=True)  # Create directory for each video's frames\n",
        "    extract_frames(video_path, frames_output_dir)\n",
        "\n",
        "print(\"Frame extraction completed and saved to Google Drive.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S6fY22g89ylI"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# Define directories for frames\n",
        "frames_real_videos_dir = '/content/drive/MyDrive/train_sample_videos/frames_real_videos'\n",
        "frames_fake_videos_dir = '/content/drive/MyDrive/train_sample_videos/frames_fake_videos'\n",
        "\n",
        "# Define a directory to save preprocessed frames\n",
        "preprocessed_real_videos_dir = '/content/drive/MyDrive/train_sample_videos/preprocessed_real_videos'\n",
        "preprocessed_fake_videos_dir = '/content/drive/MyDrive/train_sample_videos/preprocessed_fake_videos'\n",
        "\n",
        "# Create directories for preprocessed frames\n",
        "os.makedirs(preprocessed_real_videos_dir, exist_ok=True)\n",
        "os.makedirs(preprocessed_fake_videos_dir, exist_ok=True)\n",
        "\n",
        "def preprocess_frame(frame):\n",
        "    \"\"\"\n",
        "    Preprocesses a single frame. This example includes resizing and normalization.\n",
        "    Modify this function according to your preprocessing needs.\n",
        "    \"\"\"\n",
        "    # Resize frame to 224x224 (example size, adjust as needed)\n",
        "    frame = cv2.resize(frame, (224, 224))\n",
        "\n",
        "    # Normalize frame to [0, 1]\n",
        "    frame = frame / 255.0\n",
        "\n",
        "    return frame\n",
        "\n",
        "def process_frames(frames_dir, preprocessed_dir):\n",
        "    \"\"\"\n",
        "    Processes frames from the given directory and saves preprocessed frames.\n",
        "    \"\"\"\n",
        "    for video_folder in os.listdir(frames_dir):\n",
        "        video_frames_dir = os.path.join(frames_dir, video_folder)\n",
        "        preprocessed_video_frames_dir = os.path.join(preprocessed_dir, video_folder)\n",
        "        os.makedirs(preprocessed_video_frames_dir, exist_ok=True)\n",
        "\n",
        "        for frame_file in os.listdir(video_frames_dir):\n",
        "            frame_path = os.path.join(video_frames_dir, frame_file)\n",
        "            # Read the frame\n",
        "            frame = cv2.imread(frame_path)\n",
        "            if frame is not None:\n",
        "                # Preprocess the frame\n",
        "                preprocessed_frame = preprocess_frame(frame)\n",
        "                # Save the preprocessed frame\n",
        "                preprocessed_frame_path = os.path.join(preprocessed_video_frames_dir, frame_file)\n",
        "                cv2.imwrite(preprocessed_frame_path, (preprocessed_frame * 255).astype(np.uint8))  # Convert back to [0, 255]\n",
        "\n",
        "# Process and preprocess frames for real and fake videos\n",
        "process_frames(frames_real_videos_dir, preprocessed_real_videos_dir)\n",
        "process_frames(frames_fake_videos_dir, preprocessed_fake_videos_dir)\n",
        "\n",
        "print(\"Frame preprocessing completed and saved to Google Drive.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eRxJtwQW-_m9"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define directories in Google Drive and Colab environment\n",
        "preprocessed_real_videos_dir = '/content/drive/MyDrive/train_sample_videos/preprocessed_real_videos'\n",
        "preprocessed_fake_videos_dir = '/content/drive/MyDrive/train_sample_videos/preprocessed_fake_videos'\n",
        "colab_real_videos_dir = '/content/preprocessed_real_videos'\n",
        "colab_fake_videos_dir = '/content/preprocessed_fake_videos'\n",
        "\n",
        "# Create directories in Colab\n",
        "os.makedirs(colab_real_videos_dir, exist_ok=True)\n",
        "os.makedirs(colab_fake_videos_dir, exist_ok=True)\n",
        "\n",
        "# Copy preprocessed frames from Google Drive to Colab\n",
        "shutil.copytree(preprocessed_real_videos_dir, colab_real_videos_dir, dirs_exist_ok=True)\n",
        "shutil.copytree(preprocessed_fake_videos_dir, colab_fake_videos_dir, dirs_exist_ok=True)\n",
        "\n",
        "print(\"Preprocessed frames copied to Colab environment.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Iv2Q1-4OBsqI"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, real_dir, fake_dir, transform=None):\n",
        "        self.real_dir = real_dir\n",
        "\n",
        "        self.fake_dir = fake_dir\n",
        "        self.transform = transform\n",
        "\n",
        "        self.real_images = self._load_images(self.real_dir)\n",
        "        self.fake_images = self._load_images(self.fake_dir)\n",
        "\n",
        "        self.all_images = self.real_images + self.fake_images\n",
        "        self.labels = [1] * len(self.real_images) + [0] * len(self.fake_images)\n",
        "\n",
        "    def _load_images(self, dir_path):\n",
        "        images = []\n",
        "        for subdir, _, files in os.walk(dir_path):\n",
        "            for file in files:\n",
        "                file_path = os.path.join(subdir, file)\n",
        "                try:\n",
        "                    img = Image.open(file_path).convert('RGB')\n",
        "                    images.append(img)\n",
        "                except Exception as e:\n",
        "                    print(f\"Error loading image {file_path}: {e}\")\n",
        "        return images\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.all_images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img = self.all_images[idx]\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        return img, label\n",
        "\n",
        "# Define transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((64, 64)),  # Resize to fit the GAN's input size\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "# Instantiate dataset and dataloader\n",
        "dataset = CustomDataset(preprocessed_real_videos_dir, preprocessed_fake_videos_dir, transform=transform)\n",
        "dataloader = DataLoader(dataset, batch_size=64, shuffle=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "# Generator Network\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, input_dim, label_dim):\n",
        "        super(Generator, self).__init__()\n",
        "        self.label_dim = label_dim\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(input_dim + label_dim, 256),\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 512),\n",
        "            nn.BatchNorm1d(512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 1024),\n",
        "            nn.BatchNorm1d(1024),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(1024, 64*64*3),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, noise, labels):\n",
        "        input = torch.cat((noise, labels), dim=1)\n",
        "        output = self.model(input)\n",
        "        output = output.view(-1, 3, 64, 64)\n",
        "        return output\n",
        "\n",
        "# Discriminator Network\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, label_dim):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.label_dim = label_dim\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Linear(64*64*3 + label_dim, 512),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(256, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "        self.feature_layer = nn.Sequential(\n",
        "            nn.Linear(64*64*3 + label_dim, 512),\n",
        "            nn.LeakyReLU(0.2)\n",
        "        )\n",
        "\n",
        "    def forward(self, imgs, labels):\n",
        "        imgs_flat = imgs.view(imgs.size(0), -1)\n",
        "        input = torch.cat((imgs_flat, labels), dim=1)\n",
        "        features = self.feature_layer(input)\n",
        "        output = self.features(input)\n",
        "        return output, features\n"
      ],
      "metadata": {
        "id": "r14lNGNC-H_5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from torch.utils.data\n",
        "import DataLoader\n",
        "\n",
        "def train_cgan(generator, discriminator, dataloader, epochs=100, lr=0.0002, beta1=0.5, beta2=0.999, feature_csv='features.csv'):\n",
        "  device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "  generator.to(device)\n",
        "  discriminator.to(device)\n",
        "\n",
        "# Define loss function and optimizers\n",
        "criterion = nn.BCELoss()\n",
        "optimizer_g = optim.Adam(generator.parameters(), lr=lr, betas=(beta1, beta2))\n",
        "optimizer_d = optim.Adam(discriminator.parameters(), lr=lr, betas=(beta1, beta2))\n",
        "\n",
        "feature_list = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    d_loss_real_total = 0\n",
        "    d_loss_fake_total = 0\n",
        "    g_loss_total = 0\n",
        "    correct_preds = 0\n",
        "    total_preds = 0\n",
        "\n",
        "    for imgs, labels in dataloader:\n",
        "        batch_size = imgs.size(0)\n",
        "        real_labels = torch.ones(batch_size, 1).to(device)\n",
        "        fake_labels = torch.zeros(batch_size, 1).to(device)\n",
        "        labels = labels.float().unsqueeze(1).to(device)\n",
        "\n",
        "        # Train Discriminator\n",
        "        optimizer_d.zero_grad()\n",
        "\n",
        "        outputs, _ = discriminator(imgs.to(device), labels)\n",
        "        d_loss_real = criterion(outputs, real_labels)\n",
        "        d_loss_real.backward()\n",
        "\n",
        "        noise = torch.randn(batch_size, 100, device=device)\n",
        "        fake_imgs = generator(noise, labels)\n",
        "        outputs, _ = discriminator(fake_imgs.detach(), fake_labels)\n",
        "        d_loss_fake = criterion(outputs, fake_labels)\n",
        "        d_loss_fake.backward()\n",
        "\n",
        "        d_loss = d_loss_real + d_loss_fake\n",
        "        optimizer_d.step()\n",
        "\n",
        "        d_loss_real_total += d_loss_real.item()\n",
        "        d_loss_fake_total += d_loss_fake.item()\n",
        "\n",
        "        # Track discriminator accuracy\n",
        "        preds = (outputs > 0.5).float()\n",
        "        correct_preds += (preds == real_labels).sum().item()\n",
        "        total_preds += real_labels.size(0)\n",
        "\n",
        "        # Train Generator\n",
        "        optimizer_g.zero_grad()\n",
        "\n",
        "        outputs, _ = discriminator(fake_imgs, real_labels)\n",
        "        g_loss = criterion(outputs, real_labels)\n",
        "        g_loss.backward()\n",
        "\n",
        "        optimizer_g.step()\n",
        "\n",
        "        g_loss_total += g_loss.item()\n",
        "\n",
        "    # Calculate average losses and accuracy\n",
        "    avg_d_loss_real = d_loss_real_total / len(dataloader)\n",
        "    avg_d_loss_fake = d_loss_fake_total / len(dataloader)\n",
        "    avg_d_loss = (avg_d_loss_real + avg_d_loss_fake) / 2\n",
        "    avg_g_loss = g_loss_total / len(dataloader)\n",
        "    accuracy = (correct_preds / total_preds) * 100\n",
        "\n",
        "    print(f'Epoch [{epoch+1}/{epochs}] | D Loss: {avg_d_loss:.4f} | G Loss: {avg_g_loss:.4f} | Accuracy: {accuracy:.2f}%')\n",
        "\n",
        "# Save features to CSV\n",
        "## This is formatted as code\n",
        "all_features = np.vstack([item[0] for item in feature_list])\n",
        "all_labels = np.hstack([item[1] for item in feature_list])\n",
        "df = pd.DataFrame(all_features)\n",
        "df['label'] = all_labels\n",
        "df.to_csv(feature_csv, index=False)"
      ],
      "metadata": {
        "id": "CR3RZrQKRZKI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_c3gvZXqrwv8"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import h5py\n",
        "\n",
        "def csv_to_h5(csv_file, h5_file='features.h5'):\n",
        "    # Load the CSV file into a pandas DataFrame\n",
        "    df = pd.read_csv(csv_file)\n",
        "\n",
        "    # Open an HDF5 file\n",
        "    with h5py.File(h5_file, 'w') as hf:\n",
        "        # Convert DataFrame to numpy array and save as a dataset\n",
        "        hf.create_dataset('data', data=df.to_numpy())\n",
        "        # Save column names as an attribute\n",
        "        hf.attrs['columns'] = df.columns.tolist()\n",
        "\n",
        "# Example usage\n",
        "csv_file = '/content/features.csv'\n",
        "csv_to_h5(csv_file)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Zi3Ug6y0rv9"
      },
      "outputs": [],
      "source": [
        "import h5py\n",
        "\n",
        "def read_h5(h5_file='features.h5'):\n",
        "    try:\n",
        "        # Open an HDF5 file for reading\n",
        "        with h5py.File(h5_file, 'r') as hf:\n",
        "            # Access the dataset\n",
        "            if 'data' in hf:\n",
        "                data = hf['data'][:]\n",
        "            else:\n",
        "                raise KeyError(\"'data' dataset not found in the file.\")\n",
        "\n",
        "            # Access the attributes\n",
        "            if 'columns' in hf.attrs:\n",
        "                columns = hf.attrs['columns']\n",
        "            else:\n",
        "                raise KeyError(\"'columns' attribute not found in the file.\")\n",
        "\n",
        "            return data, columns\n",
        "\n",
        "    except KeyError as e:\n",
        "        print(f\"Error: {e}\")\n",
        "        print(f\"The specified object does not exist in the file: {h5_file}\")\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "\n",
        "# Example usage\n",
        "data, columns = read_h5()\n",
        "print(\"Data:\")\n",
        "print(data)\n",
        "print(\"Columns:\")\n",
        "print(columns)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import os\n",
        "import h5py\n",
        "from PIL import Image\n",
        "from torchvision import transforms, models\n",
        "import torch.nn as nn\n",
        "\n",
        "# Define preprocessing transforms\n",
        "preprocess = transforms.Compose([\n",
        "    transforms.Resize((112, 112)),  # Adjust to match the model's input size\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "def load_frames_from_directory(directory_path, num_frames=16):\n",
        "    all_frames = []\n",
        "    video_files = sorted(os.listdir(directory_path))  # Ensure consistent ordering\n",
        "    for video_file in video_files:\n",
        "        video_path = os.path.join(directory_path, video_file)\n",
        "        frames = []\n",
        "        for img_file in sorted(os.listdir(video_path)):  # Assuming frames are in subdirectories\n",
        "            img_path = os.path.join(video_path, img_file)\n",
        "            frame = Image.open(img_path).convert('RGB')  # Ensure 3 channels (RGB)\n",
        "            frame = preprocess(frame)  # Apply preprocessing\n",
        "            frames.append(frame)\n",
        "            if len(frames) >= num_frames:\n",
        "                break\n",
        "\n",
        "        if len(frames) == num_frames:\n",
        "            all_frames.append(torch.stack(frames))  # Shape: [num_frames, C, H, W]\n",
        "        else:\n",
        "            print(f\"Not enough frames found in directory: {video_path}\")\n",
        "\n",
        "    return all_frames\n",
        "\n",
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, num_layers, output_dim):\n",
        "        super(LSTMModel, self).__init__()\n",
        "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: [batch_size, seq_length, input_dim]\n",
        "        lstm_out, (hn, cn) = self.lstm(x)\n",
        "        # Use the output from the last time step\n",
        "        last_time_step_out = lstm_out[:, -1, :]  # Take the output from the last time step\n",
        "        output = self.fc(last_time_step_out)\n",
        "        return output\n",
        "\n",
        "def preprocess_frames(frames, feature_extractor):\n",
        "    features = []\n",
        "    for frame in frames:\n",
        "        frame = frame.unsqueeze(0)  # Add batch dimension\n",
        "        with torch.no_grad():\n",
        "            feature = feature_extractor(frame).squeeze()  # Extract features\n",
        "        features.append(feature)\n",
        "    return torch.stack(features)  # Shape: [num_frames, num_features]\n",
        "\n",
        "def extract_temporal_features(real_dir, fake_dir, feature_extractor, model):\n",
        "    all_features = []\n",
        "    all_labels = []\n",
        "\n",
        "    # Extract features from real videos\n",
        "    real_frames = load_frames_from_directory(real_dir)\n",
        "    for frames in real_frames:\n",
        "        features = preprocess_frames(frames, feature_extractor)\n",
        "        features_tensor = features.unsqueeze(0).to(device)  # Shape: [1, num_frames, num_features]\n",
        "        with torch.no_grad():\n",
        "            output = model(features_tensor).cpu().numpy()\n",
        "            all_features.append(output.flatten())\n",
        "            all_labels.append(1)  # Label for real videos\n",
        "\n",
        "    # Extract features from fake videos\n",
        "    fake_frames = load_frames_from_directory(fake_dir)\n",
        "    for frames in fake_frames:\n",
        "        features = preprocess_frames(frames, feature_extractor)\n",
        "        features_tensor = features.unsqueeze(0).to(device)  # Shape: [1, num_frames, num_features]\n",
        "        with torch.no_grad():\n",
        "            output = model(features_tensor).cpu().numpy()\n",
        "            all_features.append(output.flatten())\n",
        "            all_labels.append(0)  # Label for fake videos\n",
        "\n",
        "    if len(all_features) == 0:\n",
        "        raise ValueError(\"No features extracted. Check the input directories and video frames.\")\n",
        "\n",
        "    return np.array(all_features), np.array(all_labels)\n",
        "\n",
        "def save_features_to_hdf5(features, labels, hdf5_file):\n",
        "    with h5py.File(hdf5_file, 'w') as hf:\n",
        "        hf.create_dataset('features', data=features)\n",
        "        hf.create_dataset('labels', data=labels)\n",
        "\n",
        "# Define directories\n",
        "real_video_dir = '/content/preprocessed_real_videos'\n",
        "fake_video_dir = '/content/preprocessed_fake_videos'\n",
        "\n",
        "# Define dimensions\n",
        "input_dim = 2048  # Example: Flattened features from a CNN\n",
        "hidden_dim = 512\n",
        "num_layers = 2\n",
        "output_dim = 1\n",
        "\n",
        "# Instantiate feature extractor (e.g., a pre-trained CNN like ResNet)\n",
        "feature_extractor = models.resnet50(pretrained=True)\n",
        "feature_extractor.fc = nn.Identity()  # Remove the final classification layer\n",
        "\n",
        "# Instantiate the LSTM model\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "feature_extractor = feature_extractor.to(device)\n",
        "lstm_model = LSTMModel(input_dim, hidden_dim, num_layers, output_dim).to(device)\n",
        "\n",
        "# Extract features and save them\n",
        "features, labels = extract_temporal_features(real_video_dir, fake_video_dir, feature_extractor, lstm_model)\n",
        "save_features_to_hdf5(features, labels, 'temporal_features.h5')\n",
        "print(\"Features and labels saved to 'temporal_features.h5'\")\n"
      ],
      "metadata": {
        "id": "pI9CfmdCLjF8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J7dHoP4N4UQU"
      },
      "outputs": [],
      "source": [
        "import h5py\n",
        "\n",
        "# Check keys in the HDF5 file\n",
        "def check_hdf5_keys(file_path):\n",
        "    with h5py.File(file_path, 'r') as file:\n",
        "        print(\"Datasets in the file:\", list(file.keys()))\n",
        "\n",
        "# Paths to the HDF5 files\n",
        "hdf5_file_1 = '/content/features.h5'\n",
        "hdf5_file_2 = '/content/temporal_features.h5'\n",
        "\n",
        "print(\"Checking first HDF5 file:\")\n",
        "check_hdf5_keys(hdf5_file_1)\n",
        "\n",
        "print(\"Checking second HDF5 file:\")\n",
        "check_hdf5_keys(hdf5_file_2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GSYTtaq63J4w"
      },
      "outputs": [],
      "source": [
        "import h5py\n",
        "import numpy as np\n",
        "\n",
        "# Paths to the two HDF5 files you want to fuse\n",
        "hdf5_file_1 = '/content/features.h5'\n",
        "hdf5_file_2 = '/content/temporal_features.h5'\n",
        "combined_hdf5_file = '/content/drive/My Drive/new_combined_file.h5'  # Path in Google Drive\n",
        "\n",
        "def load_dataset(file_path, dataset_name):\n",
        "    try:\n",
        "        with h5py.File(file_path, 'r') as file:\n",
        "            if dataset_name in file:\n",
        "                return file[dataset_name][:]\n",
        "            else:\n",
        "                raise KeyError(f\"Dataset '{dataset_name}' does not exist in file '{file_path}'\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading dataset '{dataset_name}' from file '{file_path}': {e}\")\n",
        "        return None\n",
        "\n",
        "# List datasets in a file to debug\n",
        "def list_datasets(file_path):\n",
        "    with h5py.File(file_path, 'r') as file:\n",
        "        print(f\"Datasets in file {file_path}:\")\n",
        "        def printname(name):\n",
        "            print(name)\n",
        "        file.visit(printname)\n",
        "\n",
        "# Load datasets from the first HDF5 file\n",
        "list_datasets(hdf5_file_1)  # This will print all available datasets in features.h5\n",
        "\n",
        "# Load datasets from the second HDF5 file\n",
        "features_2 = load_dataset(hdf5_file_2, 'features')\n",
        "labels_2 = load_dataset(hdf5_file_2, 'labels')\n",
        "\n",
        "# Explicitly check if any dataset is None\n",
        "if features_2 is None:\n",
        "    raise ValueError(\"Dataset 'features' could not be loaded from the second file.\")\n",
        "if labels_2 is None:\n",
        "    raise ValueError(\"Dataset 'labels' could not be loaded from the second file.\")\n",
        "\n",
        "# Load 'data' from the first HDF5 file\n",
        "data_1 = load_dataset(hdf5_file_1, 'data')\n",
        "\n",
        "# Check if 'data' from the first file is loaded\n",
        "if data_1 is None:\n",
        "    raise ValueError(\"Dataset 'data' could not be loaded from the first file.\")\n",
        "\n",
        "# Check shapes of the datasets\n",
        "print(\"Features 2 shape:\", features_2.shape)\n",
        "print(\"Labels 2 shape:\", labels_2.shape)\n",
        "print(\"Data 1 shape:\", data_1.shape)\n",
        "\n",
        "# Ensure feature dimensions are aligned\n",
        "feature_dim = min(features_2.shape[1], data_1.shape[1])\n",
        "\n",
        "# Truncate the features to the minimum dimension size\n",
        "features_2 = features_2[:, :feature_dim]\n",
        "data_1 = data_1[:, :feature_dim]\n",
        "\n",
        "# Combine the features\n",
        "try:\n",
        "    combined_features = np.concatenate((data_1, features_2), axis=0)\n",
        "except ValueError as e:\n",
        "    print(f\"Error combining features: {e}\")\n",
        "    raise\n",
        "\n",
        "# Combine the labels (ensure they are aligned with the combined features)\n",
        "combined_labels = np.concatenate((labels_2, labels_2))  # Adjust this based on the actual labels' alignment\n",
        "\n",
        "# Check the combined data\n",
        "print(\"Combined features shape:\", combined_features.shape)\n",
        "print(\"Combined labels shape:\", combined_labels.shape)\n",
        "\n",
        "# Create a new HDF5 file and save the combined datasets\n",
        "try:\n",
        "    with h5py.File(combined_hdf5_file, 'w') as combined_file:\n",
        "        # Save combined features\n",
        "        combined_file.create_dataset('combined_features', data=combined_features)\n",
        "\n",
        "        # Save combined labels\n",
        "        combined_file.create_dataset('combined_labels', data=combined_labels)\n",
        "\n",
        "    print(\"Data successfully combined and saved to:\", combined_hdf5_file)\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error saving combined data: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1gGKC7w4aFsV"
      },
      "outputs": [],
      "source": [
        "import h5py\n",
        "\n",
        "file_path = '/content/drive/MyDrive/new_combined_file.h5'\n",
        "\n",
        "def list_datasets(file_path):\n",
        "    with h5py.File(file_path, 'r') as file:\n",
        "        print(f\"Datasets in file {file_path}:\")\n",
        "        def printname(name):\n",
        "            print(name)\n",
        "        file.visit(printname)\n",
        "\n",
        "list_datasets(file_path)  # This will print all available datasets in the HDF5 file\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UoBwHXPT76a1"
      },
      "outputs": [],
      "source": [
        "import h5py\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Define file path\n",
        "file_path = '/content/drive/MyDrive/new_combined_file.h5'\n",
        "\n",
        "# Load data\n",
        "try:\n",
        "    with h5py.File(file_path, 'r') as file:\n",
        "        # List datasets to debug\n",
        "        print(\"Datasets in file:\")\n",
        "        for name in file:\n",
        "            print(name)\n",
        "\n",
        "        # Load datasets with correct names\n",
        "        features = file['combined_features'][:]  # Updated dataset name\n",
        "        labels = file['combined_labels'][:]  # Updated dataset name\n",
        "\n",
        "    # Print shapes to confirm\n",
        "    print(\"Features shape:\", features.shape)\n",
        "    print(\"Labels shape:\", labels.shape)\n",
        "\n",
        "    # Ensure labels match the number of features\n",
        "    min_length = min(features.shape[0], len(labels))\n",
        "    features = features[:min_length]\n",
        "    labels = labels[:min_length]\n",
        "\n",
        "    # Convert labels to binary if necessary\n",
        "    # Example: Assuming labels should be 0 or 1\n",
        "    labels = (labels > 0.5).astype(int)  # Adjust this based on your label encoding\n",
        "\n",
        "    # Split the data\n",
        "    X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Print shapes for training and testing data\n",
        "    print(f\"Training features shape: {X_train.shape}\")\n",
        "    print(f\"Training labels shape: {y_train.shape}\")\n",
        "    print(f\"Test features shape: {X_test.shape}\")\n",
        "    print(f\"Test labels shape: {y_test.shape}\")\n",
        "\n",
        "except KeyError as e:\n",
        "    print(f\"KeyError: {e} - Check if the dataset names are correct.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xWo0b8TLaqkL"
      },
      "outputs": [],
      "source": [
        "import h5py\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load data\n",
        "file_path = '/content/drive/MyDrive/new_combined_file.h5'\n",
        "\n",
        "with h5py.File(file_path, 'r') as file:\n",
        "    features = file['/combined_features'][:]\n",
        "    labels = file['/combined_labels'][:]\n",
        "\n",
        "# Inspect shapes\n",
        "print(\"Features shape:\", features.shape)\n",
        "print(\"Labels shape:\", labels.shape)\n",
        "\n",
        "# Ensure number of labels matches number of features\n",
        "num_features = features.shape[0]\n",
        "num_labels = labels.shape[0]\n",
        "\n",
        "if num_features != num_labels:\n",
        "    min_length = min(num_features, num_labels)\n",
        "    features = features[:min_length]\n",
        "    labels = labels[:min_length]\n",
        "\n",
        "# Convert labels to binary if necessary\n",
        "# Example: Assuming labels should be 0 or 1\n",
        "labels = (labels > 0.5).astype(int)  # Adjust this based on your label encoding\n",
        "\n",
        "# Normalize features\n",
        "scaler = StandardScaler()\n",
        "features = scaler.fit_transform(features)\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define a more complex neural network\n",
        "class ImprovedNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ImprovedNN, self).__init__()\n",
        "        self.fc1 = nn.Linear(1, 512)  # Increased number of units\n",
        "        self.fc2 = nn.Linear(512, 256)\n",
        "        self.fc3 = nn.Linear(256, 128)\n",
        "        self.fc4 = nn.Linear(128, 1)\n",
        "        self.dropout = nn.Dropout(0.5)  # Dropout for regularization\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = torch.relu(self.fc3(x))\n",
        "        x = self.fc4(x)\n",
        "        x = self.sigmoid(x)\n",
        "        return x\n",
        "\n",
        "# Create datasets and loaders\n",
        "train_dataset = TensorDataset(torch.tensor(X_train, dtype=torch.float32),\n",
        "                              torch.tensor(y_train, dtype=torch.float32))\n",
        "test_dataset = TensorDataset(torch.tensor(X_test, dtype=torch.float32),\n",
        "                             torch.tensor(y_test, dtype=torch.float32))\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "# Initialize model, loss function, and optimizer\n",
        "model = ImprovedNN()\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(20):  # Increased number of epochs\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for data, targets in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(data).squeeze()\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}, Loss: {running_loss / len(train_loader)}\")\n",
        "\n",
        "# Evaluation\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for data, targets in test_loader:\n",
        "        outputs = model(data).squeeze()\n",
        "        predicted = (outputs > 0.5).float()\n",
        "        correct += (predicted == targets).sum().item()\n",
        "        total += targets.size(0)\n",
        "\n",
        "    accuracy = correct / total\n",
        "    print(f\"Accuracy: {accuracy * 100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "haVDkjSCRHVt"
      },
      "outputs": [],
      "source": [
        "# Save the model\n",
        "torch.save(model.state_dict(), 'simple_nn.pth')\n",
        "print(\"Model saved to 'simple_nn.pth'\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def save_model_to_h5(model, pth_path, h5_path):\n",
        "    # Load the state dict\n",
        "    state_dict = torch.load(pth_path)\n",
        "\n",
        "    # Create an HDF5 file\n",
        "    with h5py.File(h5_path, 'w') as f:\n",
        "        for key, value in state_dict.items():\n",
        "            # Convert tensor to numpy array and save to HDF5 dataset\n",
        "            f.create_dataset(key, data=value.cpu().numpy())\n",
        "\n",
        "# Save the model to HDF5 format\n",
        "save_model_to_h5(model, 'simple_nn.pth', 'new_modell.h5')\n",
        "print(\"Model saved to 'model.h5'\")"
      ],
      "metadata": {
        "id": "KckoH1QUkClW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import h5py\n",
        "\n",
        "def explore_hdf5(file_path):\n",
        "    try:\n",
        "        # Open the HDF5 file in read-only mode\n",
        "        with h5py.File(file_path, 'r') as file:\n",
        "            # Print all root level object names (aka keys)\n",
        "            print(\"Root Keys:\", list(file.keys()))\n",
        "\n",
        "            # Iterate over top-level groups and datasets\n",
        "            for key in file.keys():\n",
        "                print(f\"\\nExploring '{key}'\")\n",
        "                item = file[key]\n",
        "                if isinstance(item, h5py.Group):\n",
        "                    print(f\"Group '{key}' contains:\")\n",
        "                    for subkey in item.keys():\n",
        "                        print(f\"  Dataset '{subkey}' with shape {item[subkey].shape}\")\n",
        "                elif isinstance(item, h5py.Dataset):\n",
        "                    print(f\"Dataset '{key}' with shape {item.shape}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "\n",
        "# Replace with the actual path to your HDF5 file\n",
        "file_path = '/content/drive/MyDrive/new_combined_file.h5'\n",
        "explore_hdf5(file_path)\n"
      ],
      "metadata": {
        "id": "0E5F-zepUdLQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mEWEon2gM6Ov"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}