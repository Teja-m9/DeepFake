{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hp1w7PTW25h3",
        "outputId": "207b1199-7caa-4b47-d8ea-2bb1b5f9dc3a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "g4G4GRX526Bl",
        "outputId": "5c44a126-c2dd-4d5c-b13a-6983c4c535fe"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-85f52f4f-faa0-4928-934c-9a26cb1e5f1c\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-85f52f4f-faa0-4928-934c-9a26cb1e5f1c\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"ramtejamamidisetty\",\"key\":\"f1a08c06ba1fd4db86231291a1e0f4b4\"}'}"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yYTCbgBC3Fl6",
        "outputId": "89b5217b-fa41-451c-a1c6-b1f42dd5e44d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.6.17)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.66.5)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.0.7)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.1.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.8)\n"
          ]
        }
      ],
      "source": [
        "!pip install kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "udu1nSjV3KRk"
      },
      "outputs": [],
      "source": [
        "!mkdir -p ~/.kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HP8EQRRz3Mui"
      },
      "outputs": [],
      "source": [
        "!mv kaggle.json ~/.kaggle/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kpcothxk3O6W",
        "outputId": "c4277cc0-d721-4b3d-8589-67b9dd97b144"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  deepfake-detection-challenge.zip\n",
            "  inflating: sample_submission.csv   \n",
            "  inflating: test_videos/aassnaulhq.mp4  \n",
            "  inflating: test_videos/aayfryxljh.mp4  \n",
            "  inflating: test_videos/acazlolrpz.mp4  \n",
            "  inflating: test_videos/adohdulfwb.mp4  \n",
            "  inflating: test_videos/ahjnxtiamx.mp4  \n",
            "  inflating: test_videos/ajiyrjfyzp.mp4  \n",
            "  inflating: test_videos/aktnlyqpah.mp4  \n",
            "  inflating: test_videos/alrtntfxtd.mp4  \n",
            "  inflating: test_videos/aomqqjipcp.mp4  \n",
            "  inflating: test_videos/apedduehoy.mp4  \n",
            "  inflating: test_videos/apvzjkvnwn.mp4  \n",
            "  inflating: test_videos/aqrsylrzgi.mp4  \n",
            "  inflating: test_videos/axfhbpkdlc.mp4  \n",
            "  inflating: test_videos/ayipraspbn.mp4  \n",
            "  inflating: test_videos/bcbqxhziqz.mp4  \n",
            "  inflating: test_videos/bcvheslzrq.mp4  \n",
            "  inflating: test_videos/bdshuoldwx.mp4  \n",
            "  inflating: test_videos/bfdopzvxbi.mp4  \n",
            "  inflating: test_videos/bfjsthfhbd.mp4  \n",
            "  inflating: test_videos/bjyaxvggle.mp4  \n",
            "  inflating: test_videos/bkcyglmfci.mp4  \n",
            "  inflating: test_videos/bktkwbcawi.mp4  \n",
            "  inflating: test_videos/bkuzquigyt.mp4  \n",
            "  inflating: test_videos/blnmxntbey.mp4  \n",
            "  inflating: test_videos/blszgmxkvu.mp4  \n",
            "  inflating: test_videos/bnuwxhfahw.mp4  \n",
            "  inflating: test_videos/bofrwgeyjo.mp4  \n",
            "  inflating: test_videos/btdxnajogv.mp4  \n",
            "  inflating: test_videos/bvpeerislp.mp4  \n",
            "  inflating: test_videos/bwdmzwhdnw.mp4  \n",
            "  inflating: test_videos/bzvzpwrabw.mp4  \n",
            "  inflating: test_videos/cekarydqba.mp4  \n",
            "  inflating: test_videos/cekwtyxdoo.mp4  \n",
            "  inflating: test_videos/cjkctqqakb.mp4  \n",
            "  inflating: test_videos/cnpanmywno.mp4  \n",
            "  inflating: test_videos/cnxccbjlct.mp4  \n",
            "  inflating: test_videos/coqwgzpbhx.mp4  \n",
            "  inflating: test_videos/cosghhimnd.mp4  \n",
            "  inflating: test_videos/coujjnypba.mp4  \n",
            "  inflating: test_videos/cqhwesrciw.mp4  \n",
            "  inflating: test_videos/cqxxumarvp.mp4  \n",
            "  inflating: test_videos/csnkohqxdv.mp4  \n",
            "  inflating: test_videos/cxsvvnxpyz.mp4  \n",
            "  inflating: test_videos/czfqlbcfpa.mp4  \n",
            "  inflating: test_videos/dcqodpzomd.mp4  \n",
            "  inflating: test_videos/ddtbarpcgo.mp4  \n",
            "  inflating: test_videos/demuhxssgl.mp4  \n",
            "  inflating: test_videos/didzujjhtg.mp4  \n",
            "  inflating: test_videos/dkuqbduxev.mp4  \n",
            "  inflating: test_videos/dmmvuaikkv.mp4  \n",
            "  inflating: test_videos/dnmowthjcj.mp4  \n",
            "  inflating: test_videos/doniqevxeg.mp4  \n",
            "  inflating: test_videos/dozjwhnedd.mp4  \n",
            "  inflating: test_videos/dpevefkefv.mp4  \n",
            "  inflating: test_videos/dpmgoiwhuf.mp4  \n",
            "  inflating: test_videos/dsnxgrfdmd.mp4  \n",
            "  inflating: test_videos/dtozwcapoa.mp4  \n",
            "  inflating: test_videos/dvkdfhrpph.mp4  \n",
            "  inflating: test_videos/dvtpwatuja.mp4  \n",
            "  inflating: test_videos/dvwpvqdflx.mp4  \n",
            "  inflating: test_videos/dxfdovivlw.mp4  \n",
            "  inflating: test_videos/dxgnpnowgk.mp4  \n",
            "  inflating: test_videos/dyjklprkoc.mp4  \n",
            "  inflating: test_videos/dzkyxbbqkr.mp4  \n",
            "  inflating: test_videos/dzojiwfvba.mp4  \n",
            "  inflating: test_videos/ecumyiowzs.mp4  \n",
            "  inflating: test_videos/eisofhptvk.mp4  \n",
            "  inflating: test_videos/ekboxwrwuv.mp4  \n",
            "  inflating: test_videos/ekelfsnqof.mp4  \n",
            "  inflating: test_videos/ekvwecwltj.mp4  \n",
            "  inflating: test_videos/elackxuccp.mp4  \n",
            "  inflating: test_videos/eppyqpgewp.mp4  \n",
            "  inflating: test_videos/eqslzbqfea.mp4  \n",
            "  inflating: test_videos/eryjktdexi.mp4  \n",
            "  inflating: test_videos/esjdyghhog.mp4  \n",
            "  inflating: test_videos/esmqxszybs.mp4  \n",
            "  inflating: test_videos/espkiocpxq.mp4  \n",
            "  inflating: test_videos/etdliwticv.mp4  \n",
            "  inflating: test_videos/evysmtpnrf.mp4  \n",
            "  inflating: test_videos/eyguqfmgzh.mp4  \n",
            "  inflating: test_videos/eywdmustbb.mp4  \n",
            "  inflating: test_videos/famlupsgqm.mp4  \n",
            "  inflating: test_videos/fddmkqjwsh.mp4  \n",
            "  inflating: test_videos/fjrueenjyp.mp4  \n",
            "  inflating: test_videos/fjxovgmwnm.mp4  \n",
            "  inflating: test_videos/fmhiujydwo.mp4  \n",
            "  inflating: test_videos/fmvvmcbdrw.mp4  \n",
            "  inflating: test_videos/fneqiqpqvs.mp4  \n",
            "  inflating: test_videos/fnxgqcvlsd.mp4  \n",
            "  inflating: test_videos/fopjiyxiqd.mp4  \n",
            "  inflating: test_videos/fpevfidstw.mp4  \n",
            "  inflating: test_videos/fqgypsunzr.mp4  \n",
            "  inflating: test_videos/frqfsucgao.mp4  \n",
            "  inflating: test_videos/fsdrwikhge.mp4  \n",
            "  inflating: test_videos/fwykevubzy.mp4  \n",
            "  inflating: test_videos/fxuxxtryjn.mp4  \n",
            "  inflating: test_videos/fzvpbrzssi.mp4  \n",
            "  inflating: test_videos/gahgyuwzbu.mp4  \n",
            "  inflating: test_videos/gbnzicjyhz.mp4  \n",
            "  inflating: test_videos/gccnvdoknm.mp4  \n",
            "  inflating: test_videos/gcdtglsoqj.mp4  \n",
            "  inflating: test_videos/gfcycflhbo.mp4  \n",
            "  inflating: test_videos/gfdjzwnpyp.mp4  \n",
            "  inflating: test_videos/gfgcwxkbjd.mp4  \n",
            "  inflating: test_videos/ggdpclfcgk.mp4  \n",
            "  inflating: test_videos/ggzjfrirjh.mp4  \n",
            "  inflating: test_videos/ghnpsltzyn.mp4  \n",
            "  inflating: test_videos/gkutjglghz.mp4  \n",
            "  inflating: test_videos/gochxzemmq.mp4  \n",
            "  inflating: test_videos/gpsxfxrjrr.mp4  \n",
            "  inflating: test_videos/gqnaxievjx.mp4  \n",
            "  inflating: test_videos/gunamloolc.mp4  \n",
            "  inflating: test_videos/halvwiltfs.mp4  \n",
            "  inflating: test_videos/hbufmvbium.mp4  \n",
            "  inflating: test_videos/hcanfkwivl.mp4  \n",
            "  inflating: test_videos/hclsparpth.mp4  \n",
            "  inflating: test_videos/hefisnapds.mp4  \n",
            "  inflating: test_videos/heiyoojifp.mp4  \n",
            "  inflating: test_videos/hevcclcklc.mp4  \n",
            "  inflating: test_videos/hfsvqabzfq.mp4  \n",
            "  inflating: test_videos/hicjuubiau.mp4  \n",
            "  inflating: test_videos/hierggamuo.mp4  \n",
            "  inflating: test_videos/hitfycdavv.mp4  \n",
            "  inflating: test_videos/hnfwagcxdf.mp4  \n",
            "  inflating: test_videos/honxqdilvv.mp4  \n",
            "  inflating: test_videos/hqzwudvhih.mp4  \n",
            "  inflating: test_videos/hsbljbsgxr.mp4  \n",
            "  inflating: test_videos/hsbwhlolsn.mp4  \n",
            "  inflating: test_videos/hszwwswewp.mp4  \n",
            "  inflating: test_videos/htzbnroagi.mp4  \n",
            "  inflating: test_videos/huvlwkxoxm.mp4  \n",
            "  inflating: test_videos/hweshqpfwe.mp4  \n",
            "  inflating: test_videos/hxwtsaydal.mp4  \n",
            "  inflating: test_videos/hyjqolupxn.mp4  \n",
            "  inflating: test_videos/hzoiotcykp.mp4  \n",
            "  inflating: test_videos/hzssdinxec.mp4  \n",
            "  inflating: test_videos/ibxfxggtqh.mp4  \n",
            "  inflating: test_videos/icbsahlivv.mp4  \n",
            "  inflating: test_videos/igpvrfjdzc.mp4  \n",
            "  inflating: test_videos/ihglzxzroo.mp4  \n",
            "  inflating: test_videos/iksxzpqxzi.mp4  \n",
            "  inflating: test_videos/ilqwcbprqa.mp4  \n",
            "  inflating: test_videos/imdmhwkkni.mp4  \n",
            "  inflating: test_videos/iorbtaarte.mp4  \n",
            "  inflating: test_videos/ipkpxvwroe.mp4  \n",
            "  inflating: test_videos/ipvwtgdlre.mp4  \n",
            "  inflating: test_videos/irqzdokcws.mp4  \n",
            "  inflating: test_videos/itfsvvmslp.mp4  \n",
            "  inflating: test_videos/iznnzjvaxc.mp4  \n",
            "  inflating: test_videos/jawgcggquk.mp4  \n",
            "  inflating: test_videos/jhczqfefgw.mp4  \n",
            "  inflating: test_videos/jiavqbrkyk.mp4  \n",
            "  inflating: test_videos/jiswxuqzyz.mp4  \n",
            "  inflating: test_videos/jquevmhdvc.mp4  \n",
            "  inflating: test_videos/jsbpkpxwew.mp4  \n",
            "  inflating: test_videos/jsysgmycsx.mp4  \n",
            "  inflating: test_videos/jyfvaequfg.mp4  \n",
            "  inflating: test_videos/jyoxdvxpza.mp4  \n",
            "  inflating: test_videos/jytrvwlewz.mp4  \n",
            "  inflating: test_videos/jzmzdispyo.mp4  \n",
            "  inflating: test_videos/kcjvhgvhpt.mp4  \n",
            "  inflating: test_videos/keioymnobc.mp4  \n",
            "  inflating: test_videos/kezwvsxxzj.mp4  \n",
            "  inflating: test_videos/khpipxnsvx.mp4  \n",
            "  inflating: test_videos/kmcdjxmnoa.mp4  \n",
            "  inflating: test_videos/kmqkiihrmj.mp4  \n",
            "  inflating: test_videos/knxltsvzyu.mp4  \n",
            "  inflating: test_videos/kowiwvrjht.mp4  \n",
            "  inflating: test_videos/kqlvggiqee.mp4  \n",
            "  inflating: test_videos/kvmpmhdxly.mp4  \n",
            "  inflating: test_videos/kwfdyqofzw.mp4  \n",
            "  inflating: test_videos/lbfqksftuo.mp4  \n",
            "  inflating: test_videos/lbigytrrtr.mp4  \n",
            "  inflating: test_videos/lebzjtusnr.mp4  \n",
            "  inflating: test_videos/lhvjzhjxdp.mp4  \n",
            "  inflating: test_videos/ljauauuyka.mp4  \n",
            "  inflating: test_videos/ljouzjaqqe.mp4  \n",
            "  inflating: test_videos/llplvmcvbl.mp4  \n",
            "  inflating: test_videos/lmdyicksrv.mp4  \n",
            "  inflating: test_videos/lnhkjhyhvw.mp4  \n",
            "  inflating: test_videos/lnjkpdviqb.mp4  \n",
            "  inflating: test_videos/lpgxwdgnio.mp4  \n",
            "  inflating: test_videos/lpkgabskbw.mp4  \n",
            "  inflating: test_videos/lujvyveojc.mp4  \n",
            "  inflating: test_videos/lyoslorecs.mp4  \n",
            "  inflating: test_videos/mdfndlljvt.mp4  \n",
            "  inflating: test_videos/mkmgcxaztt.mp4  \n",
            "  inflating: test_videos/mkzaekkvej.mp4  \n",
            "  inflating: test_videos/mllzkpgatp.mp4  \n",
            "  inflating: test_videos/mnowxangqx.mp4  \n",
            "  inflating: test_videos/mnzabbkpmt.mp4  \n",
            "  inflating: test_videos/mohiqoogpb.mp4  \n",
            "  inflating: test_videos/mszblrdprw.mp4  \n",
            "  inflating: test_videos/mwnibuujwz.mp4  \n",
            "  inflating: test_videos/mwwploizlj.mp4  \n",
            "  inflating: test_videos/mxahsihabr.mp4  \n",
            "  inflating: test_videos/mxlipjhmqk.mp4  \n",
            "  inflating: test_videos/ncmpqwmnzb.mp4  \n",
            "  inflating: test_videos/ncoeewrdlo.mp4  \n",
            "  inflating: test_videos/ndikguxzek.mp4  \n",
            "  inflating: test_videos/nikynwcvuh.mp4  \n",
            "  inflating: test_videos/njzshtfmcw.mp4  \n",
            "  inflating: test_videos/nkhzxomani.mp4  \n",
            "  inflating: test_videos/novarhxpbj.mp4  \n",
            "  inflating: test_videos/nplviymzlg.mp4  \n",
            "  inflating: test_videos/nswtvttxre.mp4  \n",
            "  inflating: test_videos/nthpnwylxo.mp4  \n",
            "  inflating: test_videos/nwvloufjty.mp4  \n",
            "  inflating: test_videos/nwvsbmyndn.mp4  \n",
            "  inflating: test_videos/nxgzmgzkfv.mp4  \n",
            "  inflating: test_videos/nxnmkytwze.mp4  \n",
            "  inflating: test_videos/nxzgekegsp.mp4  \n",
            "  inflating: test_videos/nycmyuzpml.mp4  \n",
            "  inflating: test_videos/nymodlmxni.mp4  \n",
            "  inflating: test_videos/oaguiggjyv.mp4  \n",
            "  inflating: test_videos/ocgdbrgmtq.mp4  \n",
            "  inflating: test_videos/oefukgnvel.mp4  \n",
            "  inflating: test_videos/oelqpetgwj.mp4  \n",
            "  inflating: test_videos/ojsxxkalat.mp4  \n",
            "  inflating: test_videos/okgelildpc.mp4  \n",
            "  inflating: test_videos/omphqltjdd.mp4  \n",
            "  inflating: test_videos/ooafcxxfrs.mp4  \n",
            "  inflating: test_videos/oocincvedt.mp4  \n",
            "  inflating: test_videos/oojxonbgow.mp4  \n",
            "  inflating: test_videos/opvqdabdap.mp4  \n",
            "  inflating: test_videos/orekjthsef.mp4  \n",
            "  inflating: test_videos/orixbcfvdz.mp4  \n",
            "  inflating: test_videos/ouaowjmigq.mp4  \n",
            "  inflating: test_videos/owaogcehvc.mp4  \n",
            "  inflating: test_videos/oyqgwjdwaj.mp4  \n",
            "  inflating: test_videos/oysopgovhu.mp4  \n",
            "  inflating: test_videos/papagllumt.mp4  \n",
            "  inflating: test_videos/pcoxcmtroa.mp4  \n",
            "  inflating: test_videos/pcyswtgick.mp4  \n",
            "  inflating: test_videos/pdswwyyntw.mp4  \n",
            "  inflating: test_videos/pdufsewrec.mp4  \n",
            "  inflating: test_videos/petmyhjclt.mp4  \n",
            "  inflating: test_videos/phjvutxpoi.mp4  \n",
            "  inflating: test_videos/pqdeutauqc.mp4  \n",
            "  inflating: test_videos/pqthmvwonf.mp4  \n",
            "  inflating: test_videos/prhmixykhr.mp4  \n",
            "  inflating: test_videos/prwsfljdjo.mp4  \n",
            "  inflating: test_videos/psesikjaxx.mp4  \n",
            "  inflating: test_videos/ptbfnkajyi.mp4  \n",
            "  inflating: test_videos/ptbnewtvon.mp4  \n",
            "  inflating: test_videos/pxcfrszlgi.mp4  \n",
            "  inflating: test_videos/pxjkzvqomp.mp4  \n",
            "  inflating: test_videos/qarqtkvgby.mp4  \n",
            "  inflating: test_videos/qcbkztamqc.mp4  \n",
            "  inflating: test_videos/qclpbcbgeq.mp4  \n",
            "  inflating: test_videos/qdqdsaiitt.mp4  \n",
            "  inflating: test_videos/qhkzlnzruj.mp4  \n",
            "  inflating: test_videos/qhsehzgxqj.mp4  \n",
            "  inflating: test_videos/qlqhjcshpk.mp4  \n",
            "  inflating: test_videos/qlvsqdroqo.mp4  \n",
            "  inflating: test_videos/qooxnxqqjb.mp4  \n",
            "  inflating: test_videos/qqnlrngaft.mp4  \n",
            "  inflating: test_videos/qsjiypnjwi.mp4  \n",
            "  inflating: test_videos/qswlzfgcgj.mp4  \n",
            "  inflating: test_videos/qxyrtwozyw.mp4  \n",
            "  inflating: test_videos/qyyhuvqmyf.mp4  \n",
            "  inflating: test_videos/rcecrgeotc.mp4  \n",
            "  inflating: test_videos/rcjfxxhcal.mp4  \n",
            "  inflating: test_videos/rerpivllud.mp4  \n",
            "  inflating: test_videos/rfjuhbnlro.mp4  \n",
            "  inflating: test_videos/rfwxcinshk.mp4  \n",
            "  inflating: test_videos/rklawjhbpv.mp4  \n",
            "  inflating: test_videos/rktrpsdlci.mp4  \n",
            "  inflating: test_videos/rmlzgerevr.mp4  \n",
            "  inflating: test_videos/rmufsuogzn.mp4  \n",
            "  inflating: test_videos/rnfcjxynfa.mp4  \n",
            "  inflating: test_videos/rrrfjhugvb.mp4  \n",
            "  inflating: test_videos/rtpbawlmxr.mp4  \n",
            "  inflating: test_videos/ruhtnngrqv.mp4  \n",
            "  inflating: test_videos/rukyxomwcx.mp4  \n",
            "  inflating: test_videos/rvvpazsffd.mp4  \n",
            "  inflating: test_videos/rxdoimqble.mp4  \n",
            "  inflating: test_videos/ryxaqpfubf.mp4  \n",
            "  inflating: test_videos/scbdenmaed.mp4  \n",
            "  inflating: test_videos/scrbqgpvzz.mp4  \n",
            "  inflating: test_videos/sfsayjgzrh.mp4  \n",
            "  inflating: test_videos/shnsajrsow.mp4  \n",
            "  inflating: test_videos/siebfpwuhu.mp4  \n",
            "  inflating: test_videos/sjinmmbipg.mp4  \n",
            "  inflating: test_videos/sjkfxrlxxs.mp4  \n",
            "  inflating: test_videos/sjwywglgym.mp4  \n",
            "  inflating: test_videos/sktpeppbkc.mp4  \n",
            "  inflating: test_videos/sngjsueuhs.mp4  \n",
            "  inflating: test_videos/snlyjbnpgw.mp4  \n",
            "  inflating: test_videos/sodvtfqbpf.mp4  \n",
            "  inflating: test_videos/sqixhnilfm.mp4  \n",
            "  inflating: test_videos/srfefmyjvt.mp4  \n",
            "  inflating: test_videos/sufvvwmbha.mp4  \n",
            "  inflating: test_videos/swsaoktwgi.mp4  \n",
            "  inflating: test_videos/sylnrepacf.mp4  \n",
            "  inflating: test_videos/syuxttuyhm.mp4  \n",
            "  inflating: test_videos/syxobtuucp.mp4  \n",
            "  inflating: test_videos/sznkemeqro.mp4  \n",
            "  inflating: test_videos/tejfudfgpq.mp4  \n",
            "  inflating: test_videos/temeqbmzxu.mp4  \n",
            "  inflating: test_videos/temjefwaas.mp4  \n",
            "  inflating: test_videos/tgawasvbbr.mp4  \n",
            "  inflating: test_videos/tjuihawuqm.mp4  \n",
            "  inflating: test_videos/tjywwgftmv.mp4  \n",
            "  inflating: test_videos/toinozytsp.mp4  \n",
            "  inflating: test_videos/tvhjcfnqtg.mp4  \n",
            "  inflating: test_videos/txmnoyiyte.mp4  \n",
            "  inflating: test_videos/txnmkabufs.mp4  \n",
            "  inflating: test_videos/tyjpjpglgx.mp4  \n",
            "  inflating: test_videos/tynfsthodx.mp4  \n",
            "  inflating: test_videos/ucthmsajay.mp4  \n",
            "  inflating: test_videos/udxqbhgvvx.mp4  \n",
            "  inflating: test_videos/uhakqelqri.mp4  \n",
            "  inflating: test_videos/uhrqlmlclw.mp4  \n",
            "  inflating: test_videos/uoccaiathd.mp4  \n",
            "  inflating: test_videos/upmgtackuf.mp4  \n",
            "  inflating: test_videos/uqvxjfpwdo.mp4  \n",
            "  inflating: test_videos/usqqvxcjmg.mp4  \n",
            "  inflating: test_videos/uubgqnvfdl.mp4  \n",
            "  inflating: test_videos/uvrzaczrbx.mp4  \n",
            "  inflating: test_videos/uxuvkrjhws.mp4  \n",
            "  inflating: test_videos/vajkicalux.mp4  \n",
            "  inflating: test_videos/vbcgoyxsvn.mp4  \n",
            "  inflating: test_videos/vdtsbqidjb.mp4  \n",
            "  inflating: test_videos/vhbbwdflyh.mp4  \n",
            "  inflating: test_videos/viteugozpv.mp4  \n",
            "  inflating: test_videos/vizerpsvbz.mp4  \n",
            "  inflating: test_videos/vjljdfopjg.mp4  \n",
            "  inflating: test_videos/vmxfwxgdei.mp4  \n",
            "  inflating: test_videos/vnlzxqwthl.mp4  \n",
            "  inflating: test_videos/voawxrmqyl.mp4  \n",
            "  inflating: test_videos/vokrpfjpeb.mp4  \n",
            "  inflating: test_videos/vssmlqoiti.mp4  \n",
            "  inflating: test_videos/vtunvalyji.mp4  \n",
            "  inflating: test_videos/vurjckblge.mp4  \n",
            "  inflating: test_videos/vvfszaosiv.mp4  \n",
            "  inflating: test_videos/vwxednhlwz.mp4  \n",
            "  inflating: test_videos/wadvzjhwtw.mp4  \n",
            "  inflating: test_videos/waucvvmtkq.mp4  \n",
            "  inflating: test_videos/wclvkepakb.mp4  \n",
            "  inflating: test_videos/wcqvzujamg.mp4  \n",
            "  inflating: test_videos/wcssbghcpc.mp4  \n",
            "  inflating: test_videos/wcvsqnplsk.mp4  \n",
            "  inflating: test_videos/wfzjxzhdkj.mp4  \n",
            "  inflating: test_videos/wixbuuzygv.mp4  \n",
            "  inflating: test_videos/wjhpisoeaj.mp4  \n",
            "  inflating: test_videos/wmoqzxddkb.mp4  \n",
            "  inflating: test_videos/wndursivcx.mp4  \n",
            "  inflating: test_videos/wnlubukrki.mp4  \n",
            "  inflating: test_videos/wqysrieiqu.mp4  \n",
            "  inflating: test_videos/wvgviwnwob.mp4  \n",
            "  inflating: test_videos/wynotylpnm.mp4  \n",
            "  inflating: test_videos/xcruhaccxc.mp4  \n",
            "  inflating: test_videos/xdezcezszc.mp4  \n",
            "  inflating: test_videos/xhtppuyqdr.mp4  \n",
            "  inflating: test_videos/xitgdpzbxv.mp4  \n",
            "  inflating: test_videos/xjvxtuakyd.mp4  \n",
            "  inflating: test_videos/xljemofssi.mp4  \n",
            "  inflating: test_videos/xmkwsnuzyq.mp4  \n",
            "  inflating: test_videos/xphdfgmfmz.mp4  \n",
            "  inflating: test_videos/xrtvqhdibb.mp4  \n",
            "  inflating: test_videos/xugmhbetrw.mp4  \n",
            "  inflating: test_videos/xxzefxwyku.mp4  \n",
            "  inflating: test_videos/yarpxfqejd.mp4  \n",
            "  inflating: test_videos/yaxgpxhavq.mp4  \n",
            "  inflating: test_videos/ybbrkacebd.mp4  \n",
            "  inflating: test_videos/yhjlnisfel.mp4  \n",
            "  inflating: test_videos/yhylappzid.mp4  \n",
            "  inflating: test_videos/yietrwuncf.mp4  \n",
            "  inflating: test_videos/yiykshcbaz.mp4  \n",
            "  inflating: test_videos/yljecirelf.mp4  \n",
            "  inflating: test_videos/yllztsrwjw.mp4  \n",
            "  inflating: test_videos/ylxwcwhjjd.mp4  \n",
            "  inflating: test_videos/yoyhmxtrys.mp4  \n",
            "  inflating: test_videos/ypbtpunjvm.mp4  \n",
            "  inflating: test_videos/yqhouqakbx.mp4  \n",
            "  inflating: test_videos/yronlutbgm.mp4  \n",
            "  inflating: test_videos/ystdtnetgj.mp4  \n",
            "  inflating: test_videos/ytddugrwph.mp4  \n",
            "  inflating: test_videos/ytopzxrswu.mp4  \n",
            "  inflating: test_videos/ywauoonmlr.mp4  \n",
            "  inflating: test_videos/ywxpquomgt.mp4  \n",
            "  inflating: test_videos/yxadevzohx.mp4  \n",
            "  inflating: test_videos/yxirnfyijn.mp4  \n",
            "  inflating: test_videos/yxvmusxvcz.mp4  \n",
            "  inflating: test_videos/yzuestxcbq.mp4  \n",
            "  inflating: test_videos/zbgssotnjm.mp4  \n",
            "  inflating: test_videos/zcxcmneefk.mp4  \n",
            "  inflating: test_videos/zfobicuigx.mp4  \n",
            "  inflating: test_videos/zfrrixsimm.mp4  \n",
            "  inflating: test_videos/zgbhzkditd.mp4  \n",
            "  inflating: test_videos/zgjosltkie.mp4  \n",
            "  inflating: test_videos/ziipxxchai.mp4  \n",
            "  inflating: test_videos/zmxeiipnqb.mp4  \n",
            "  inflating: test_videos/ztyuiqrhdk.mp4  \n",
            "  inflating: test_videos/ztyvglkcsf.mp4  \n",
            "  inflating: test_videos/zuwwbbusgl.mp4  \n",
            "  inflating: test_videos/zxacihctqp.mp4  \n",
            "  inflating: test_videos/zyufpqvpyu.mp4  \n",
            "  inflating: test_videos/zzmgnglanj.mp4  \n",
            "  inflating: train_sample_videos/aagfhgtpmv.mp4  \n",
            "  inflating: train_sample_videos/aapnvogymq.mp4  \n",
            "  inflating: train_sample_videos/abarnvbtwb.mp4  \n",
            "  inflating: train_sample_videos/abofeumbvv.mp4  \n",
            "  inflating: train_sample_videos/abqwwspghj.mp4  \n",
            "  inflating: train_sample_videos/acifjvzvpm.mp4  \n",
            "  inflating: train_sample_videos/acqfdwsrhi.mp4  \n",
            "  inflating: train_sample_videos/acxnxvbsxk.mp4  \n",
            "  inflating: train_sample_videos/acxwigylke.mp4  \n",
            "  inflating: train_sample_videos/aczrgyricp.mp4  \n",
            "  inflating: train_sample_videos/adhsbajydo.mp4  \n",
            "  inflating: train_sample_videos/adohikbdaz.mp4  \n",
            "  inflating: train_sample_videos/adylbeequz.mp4  \n",
            "  inflating: train_sample_videos/aelfnikyqj.mp4  \n",
            "  inflating: train_sample_videos/aelzhcnwgf.mp4  \n",
            "  inflating: train_sample_videos/aettqgevhz.mp4  \n",
            "  inflating: train_sample_videos/aevrfsexku.mp4  \n",
            "  inflating: train_sample_videos/afoovlsmtx.mp4  \n",
            "  inflating: train_sample_videos/agdkmztvby.mp4  \n",
            "  inflating: train_sample_videos/agqphdxmwt.mp4  \n",
            "  inflating: train_sample_videos/agrmhtjdlk.mp4  \n",
            "  inflating: train_sample_videos/ahbweevwpv.mp4  \n",
            "  inflating: train_sample_videos/ahdbuwqxit.mp4  \n",
            "  inflating: train_sample_videos/ahfazfbntc.mp4  \n",
            "  inflating: train_sample_videos/ahqqqilsxt.mp4  \n",
            "  inflating: train_sample_videos/aipfdnwpoo.mp4  \n",
            "  inflating: train_sample_videos/ajqslcypsw.mp4  \n",
            "  inflating: train_sample_videos/ajwpjhrbcv.mp4  \n",
            "  inflating: train_sample_videos/aklqzsddfl.mp4  \n",
            "  inflating: train_sample_videos/aknbdpmgua.mp4  \n",
            "  inflating: train_sample_videos/aknmpoonls.mp4  \n",
            "  inflating: train_sample_videos/akvmwkdyuv.mp4  \n",
            "  inflating: train_sample_videos/akxoopqjqz.mp4  \n",
            "  inflating: train_sample_videos/akzbnazxtz.mp4  \n",
            "  inflating: train_sample_videos/aladcziidp.mp4  \n",
            "  inflating: train_sample_videos/alaijyygdv.mp4  \n",
            "  inflating: train_sample_videos/alninxcyhg.mp4  \n",
            "  inflating: train_sample_videos/altziddtxi.mp4  \n",
            "  inflating: train_sample_videos/alvgwypubw.mp4  \n",
            "  inflating: train_sample_videos/amaivqofda.mp4  \n",
            "  inflating: train_sample_videos/amowujxmzc.mp4  \n",
            "  inflating: train_sample_videos/andaxzscny.mp4  \n",
            "  inflating: train_sample_videos/aneclqfpbt.mp4  \n",
            "  inflating: train_sample_videos/anpuvshzoo.mp4  \n",
            "  inflating: train_sample_videos/aorjvbyxhw.mp4  \n",
            "  inflating: train_sample_videos/apatcsqejh.mp4  \n",
            "  inflating: train_sample_videos/apgjqzkoma.mp4  \n",
            "  inflating: train_sample_videos/apogckdfrz.mp4  \n",
            "  inflating: train_sample_videos/aqpnvjhuzw.mp4  \n",
            "  inflating: train_sample_videos/arkroixhey.mp4  \n",
            "  inflating: train_sample_videos/arlmiizoob.mp4  \n",
            "  inflating: train_sample_videos/arrhsnjqku.mp4  \n",
            "  inflating: train_sample_videos/asaxgevnnp.mp4  \n",
            "  inflating: train_sample_videos/asdpeebotb.mp4  \n",
            "  inflating: train_sample_videos/aslsvlvpth.mp4  \n",
            "  inflating: train_sample_videos/asmpfjfzif.mp4  \n",
            "  inflating: train_sample_videos/asvcrfdpnq.mp4  \n",
            "  inflating: train_sample_videos/atkdltyyen.mp4  \n",
            "  inflating: train_sample_videos/atvmxvwyns.mp4  \n",
            "  inflating: train_sample_videos/atxvxouljq.mp4  \n",
            "  inflating: train_sample_videos/atyntldecu.mp4  \n",
            "  inflating: train_sample_videos/atzdznmder.mp4  \n",
            "  inflating: train_sample_videos/aufmsmnoye.mp4  \n",
            "  inflating: train_sample_videos/augtsuxpzc.mp4  \n",
            "  inflating: train_sample_videos/avfitoutyn.mp4  \n",
            "  inflating: train_sample_videos/avgiuextiz.mp4  \n",
            "  inflating: train_sample_videos/avibnnhwhp.mp4  \n",
            "  inflating: train_sample_videos/avmjormvsx.mp4  \n",
            "  inflating: train_sample_videos/avnqydkqjj.mp4  \n",
            "  inflating: train_sample_videos/avssvvsdhz.mp4  \n",
            "  inflating: train_sample_videos/avtycwsgyb.mp4  \n",
            "  inflating: train_sample_videos/avvdgsennp.mp4  \n",
            "  inflating: train_sample_videos/avywawptfc.mp4  \n",
            "  inflating: train_sample_videos/awhmfnnjih.mp4  \n",
            "  inflating: train_sample_videos/awnwkrqibf.mp4  \n",
            "  inflating: train_sample_videos/awukslzjra.mp4  \n",
            "  inflating: train_sample_videos/axczxisdtb.mp4  \n",
            "  inflating: train_sample_videos/axntxmycwd.mp4  \n",
            "  inflating: train_sample_videos/axoygtekut.mp4  \n",
            "  inflating: train_sample_videos/axwgcsyphv.mp4  \n",
            "  inflating: train_sample_videos/axwovszumc.mp4  \n",
            "  inflating: train_sample_videos/aybgughjxh.mp4  \n",
            "  inflating: train_sample_videos/aybumesmpk.mp4  \n",
            "  inflating: train_sample_videos/ayqvfdhslr.mp4  \n",
            "  inflating: train_sample_videos/aytzyidmgs.mp4  \n",
            "  inflating: train_sample_videos/azpuxunqyo.mp4  \n",
            "  inflating: train_sample_videos/azsmewqghg.mp4  \n",
            "  inflating: train_sample_videos/bahdpoesir.mp4  \n",
            "  inflating: train_sample_videos/bbhpvrmbse.mp4  \n",
            "  inflating: train_sample_videos/bbhtdfuqxq.mp4  \n",
            "  inflating: train_sample_videos/bbvgxeczei.mp4  \n",
            "  inflating: train_sample_videos/bchnbulevv.mp4  \n",
            "  inflating: train_sample_videos/bctvsmddgq.mp4  \n",
            "  inflating: train_sample_videos/bdbhekrrwo.mp4  \n",
            "  inflating: train_sample_videos/bddjdhzfze.mp4  \n",
            "  inflating: train_sample_videos/bdgipnyobr.mp4  \n",
            "  inflating: train_sample_videos/bdnaqemxmr.mp4  \n",
            "  inflating: train_sample_videos/bdxuhamuqx.mp4  \n",
            "  inflating: train_sample_videos/beboztfcme.mp4  \n",
            "  inflating: train_sample_videos/bejhvclboh.mp4  \n",
            "  inflating: train_sample_videos/benmsfzfaz.mp4  \n",
            "  inflating: train_sample_videos/beyebyhrph.mp4  \n",
            "  inflating: train_sample_videos/bffwsjxghk.mp4  \n",
            "  inflating: train_sample_videos/bgaogsjehq.mp4  \n",
            "  inflating: train_sample_videos/bggsurpgpr.mp4  \n",
            "  inflating: train_sample_videos/bghphrsfxf.mp4  \n",
            "  inflating: train_sample_videos/bgmlwsoamc.mp4  \n",
            "  inflating: train_sample_videos/bguwlyazau.mp4  \n",
            "  inflating: train_sample_videos/bgvhtpzknn.mp4  \n",
            "  inflating: train_sample_videos/bgwmmujlmc.mp4  \n",
            "  inflating: train_sample_videos/bhaaboftbc.mp4  \n",
            "  inflating: train_sample_videos/bhbdugnurr.mp4  \n",
            "  inflating: train_sample_videos/bhpwpydzpo.mp4  \n",
            "  inflating: train_sample_videos/bhsluedavd.mp4  \n",
            "  inflating: train_sample_videos/bilnggbxgu.mp4  \n",
            "  inflating: train_sample_videos/bjjbwsqjir.mp4  \n",
            "  inflating: train_sample_videos/bjkmjilrxp.mp4  \n",
            "  inflating: train_sample_videos/bjsmaqefoi.mp4  \n",
            "  inflating: train_sample_videos/bkmdzhfzfh.mp4  \n",
            "  inflating: train_sample_videos/bkvetcojbt.mp4  \n",
            "  inflating: train_sample_videos/bkwxhglwct.mp4  \n",
            "  inflating: train_sample_videos/blpchvmhxx.mp4  \n",
            "  inflating: train_sample_videos/blzydqdfem.mp4  \n",
            "  inflating: train_sample_videos/bmbbkwmxqj.mp4  \n",
            "  inflating: train_sample_videos/bmehkyanbj.mp4  \n",
            "  inflating: train_sample_videos/bmhvktyiwp.mp4  \n",
            "  inflating: train_sample_videos/bmioepcpsx.mp4  \n",
            "  inflating: train_sample_videos/bmjmjmbglm.mp4  \n",
            "  inflating: train_sample_videos/bmjzrlszhi.mp4  \n",
            "  inflating: train_sample_videos/bnbuonyoje.mp4  \n",
            "  inflating: train_sample_videos/bndybcqhfr.mp4  \n",
            "  inflating: train_sample_videos/bnjcdrfuov.mp4  \n",
            "  inflating: train_sample_videos/bntlodcfeg.mp4  \n",
            "  inflating: train_sample_videos/bofqajtwve.mp4  \n",
            "  inflating: train_sample_videos/boovltmuwi.mp4  \n",
            "  inflating: train_sample_videos/bopqhhalml.mp4  \n",
            "  inflating: train_sample_videos/bourlmzsio.mp4  \n",
            "  inflating: train_sample_videos/bpapbctoao.mp4  \n",
            "  inflating: train_sample_videos/bpwzipqtxf.mp4  \n",
            "  inflating: train_sample_videos/bpxckdzddv.mp4  \n",
            "  inflating: train_sample_videos/bqdjzqhcft.mp4  \n",
            "  inflating: train_sample_videos/bqeiblbxtl.mp4  \n",
            "  inflating: train_sample_videos/bqhtpqmmqp.mp4  \n",
            "  inflating: train_sample_videos/bqkdbcqjvb.mp4  \n",
            "  inflating: train_sample_videos/bqnymlsayl.mp4  \n",
            "  inflating: train_sample_videos/bqqpbzjgup.mp4  \n",
            "  inflating: train_sample_videos/bqtuuwzdtr.mp4  \n",
            "  inflating: train_sample_videos/brhalypwoo.mp4  \n",
            "  inflating: train_sample_videos/brvqtabyxj.mp4  \n",
            "  inflating: train_sample_videos/brwrlczjvi.mp4  \n",
            "  inflating: train_sample_videos/bseamdrpbj.mp4  \n",
            "  inflating: train_sample_videos/bsfmwclnqy.mp4  \n",
            "  inflating: train_sample_videos/bsqgziaylx.mp4  \n",
            "  inflating: train_sample_videos/btiysiskpf.mp4  \n",
            "  inflating: train_sample_videos/btjlfpzbdu.mp4  \n",
            "  inflating: train_sample_videos/btjwbtsgln.mp4  \n",
            "  inflating: train_sample_videos/btmsngnqhv.mp4  \n",
            "  inflating: train_sample_videos/btohlidmru.mp4  \n",
            "  inflating: train_sample_videos/btugrnoton.mp4  \n",
            "  inflating: train_sample_videos/btunxncpjh.mp4  \n",
            "  inflating: train_sample_videos/btxlttbpkj.mp4  \n",
            "  inflating: train_sample_videos/bulkxhhknf.mp4  \n",
            "  inflating: train_sample_videos/bvgwelbeof.mp4  \n",
            "  inflating: train_sample_videos/bvzjkezkms.mp4  \n",
            "  inflating: train_sample_videos/bweezhfpzp.mp4  \n",
            "  inflating: train_sample_videos/bwhlgysghg.mp4  \n",
            "  inflating: train_sample_videos/bwipwzzxxu.mp4  \n",
            "  inflating: train_sample_videos/bwuwstvsbw.mp4  \n",
            "  inflating: train_sample_videos/bxzakyopjf.mp4  \n",
            "  inflating: train_sample_videos/bydaidkpdp.mp4  \n",
            "  inflating: train_sample_videos/byfenovjnf.mp4  \n",
            "  inflating: train_sample_videos/byijojkdba.mp4  \n",
            "  inflating: train_sample_videos/byofowlkki.mp4  \n",
            "  inflating: train_sample_videos/byqzyxifza.mp4  \n",
            "  inflating: train_sample_videos/byunigvnay.mp4  \n",
            "  inflating: train_sample_videos/byyqectxqa.mp4  \n",
            "  inflating: train_sample_videos/bzmdrafeex.mp4  \n",
            "  inflating: train_sample_videos/bzythlfnhq.mp4  \n",
            "  inflating: train_sample_videos/caifxvsozs.mp4  \n",
            "  inflating: train_sample_videos/caqbrkogkb.mp4  \n",
            "  inflating: train_sample_videos/cbbibzcoih.mp4  \n",
            "  inflating: train_sample_videos/cbltdtxglo.mp4  \n",
            "  inflating: train_sample_videos/ccfoszqabv.mp4  \n",
            "  inflating: train_sample_videos/ccmonzqfrz.mp4  \n",
            "  inflating: train_sample_videos/cdaxixbosp.mp4  \n",
            "  inflating: train_sample_videos/cdbsbdymzd.mp4  \n",
            "  inflating: train_sample_videos/cdphtzqrvp.mp4  \n",
            "  inflating: train_sample_videos/cdyakrxkia.mp4  \n",
            "  inflating: train_sample_videos/cepxysienc.mp4  \n",
            "  inflating: train_sample_videos/cettndmvzl.mp4  \n",
            "  inflating: train_sample_videos/ceymbecxnj.mp4  \n",
            "  inflating: train_sample_videos/cferslmfwh.mp4  \n",
            "  inflating: train_sample_videos/cffffbcywc.mp4  \n",
            "  inflating: train_sample_videos/cfxkpiweqt.mp4  \n",
            "  inflating: train_sample_videos/cfyduhpbps.mp4  \n",
            "  inflating: train_sample_videos/cglxirfaey.mp4  \n",
            "  inflating: train_sample_videos/cgvrgibpfo.mp4  \n",
            "  inflating: train_sample_videos/chtapglbcj.mp4  \n",
            "  inflating: train_sample_videos/chviwxsfhg.mp4  \n",
            "  inflating: train_sample_videos/chzieimrwu.mp4  \n",
            "  inflating: train_sample_videos/ciyoudyhly.mp4  \n",
            "  inflating: train_sample_videos/cizlkenljw.mp4  \n",
            "  inflating: train_sample_videos/ckbdwedgmc.mp4  \n",
            "  inflating: train_sample_videos/ckjaibzfxa.mp4  \n",
            "  inflating: train_sample_videos/ckkuyewywx.mp4  \n",
            "  inflating: train_sample_videos/cknyxaqouy.mp4  \n",
            "  inflating: train_sample_videos/cksanfsjhc.mp4  \n",
            "  inflating: train_sample_videos/clihsshdkq.mp4  \n",
            "  inflating: train_sample_videos/clrycekyst.mp4  \n",
            "  inflating: train_sample_videos/cmbzllswnl.mp4  \n",
            "  inflating: train_sample_videos/cmxcfkrjiv.mp4  \n",
            "  inflating: train_sample_videos/cnilkgvfei.mp4  \n",
            "  inflating: train_sample_videos/coadfnerlk.mp4  \n",
            "  inflating: train_sample_videos/cobjrlugvp.mp4  \n",
            "  inflating: train_sample_videos/covdcysmbi.mp4  \n",
            "  inflating: train_sample_videos/cpjxareypw.mp4  \n",
            "  inflating: train_sample_videos/cppdvdejkc.mp4  \n",
            "  inflating: train_sample_videos/cprhtltsjp.mp4  \n",
            "  inflating: train_sample_videos/cqfugiqupm.mp4  \n",
            "  inflating: train_sample_videos/cqhngvpgyi.mp4  \n",
            "  inflating: train_sample_videos/cqrskwiqng.mp4  \n",
            "  inflating: train_sample_videos/crezycjqyk.mp4  \n",
            "  inflating: train_sample_videos/crktehraph.mp4  \n",
            "  inflating: train_sample_videos/crzfebnfgb.mp4  \n",
            "  inflating: train_sample_videos/cthdnahrkh.mp4  \n",
            "  inflating: train_sample_videos/ctpqeykqdp.mp4  \n",
            "  inflating: train_sample_videos/cttqtsjvgn.mp4  \n",
            "  inflating: train_sample_videos/ctzmavwror.mp4  \n",
            "  inflating: train_sample_videos/curpwogllm.mp4  \n",
            "  inflating: train_sample_videos/cuzrgrbvil.mp4  \n",
            "  inflating: train_sample_videos/cvaksbpssm.mp4  \n",
            "  inflating: train_sample_videos/cwbacdwrzo.mp4  \n",
            "  inflating: train_sample_videos/cwqlvzefpg.mp4  \n",
            "  inflating: train_sample_videos/cwrtyzndpx.mp4  \n",
            "  inflating: train_sample_videos/cwsbspfzck.mp4  \n",
            "  inflating: train_sample_videos/cwwandrkus.mp4  \n",
            "  inflating: train_sample_videos/cxfujlvsuw.mp4  \n",
            "  inflating: train_sample_videos/cxrfacemmq.mp4  \n",
            "  inflating: train_sample_videos/cxttmymlbn.mp4  \n",
            "  inflating: train_sample_videos/cyboodqqyr.mp4  \n",
            "  inflating: train_sample_videos/cycacemkmt.mp4  \n",
            "  inflating: train_sample_videos/cyclgfjdrv.mp4  \n",
            "  inflating: train_sample_videos/cyxlcuyznd.mp4  \n",
            "  inflating: train_sample_videos/czfunozvwp.mp4  \n",
            "  inflating: train_sample_videos/czkdanyadc.mp4  \n",
            "  inflating: train_sample_videos/czmqpxrqoh.mp4  \n",
            "  inflating: train_sample_videos/dafhtipaml.mp4  \n",
            "  inflating: train_sample_videos/dakiztgtnw.mp4  \n",
            "  inflating: train_sample_videos/dakqwktlbi.mp4  \n",
            "  inflating: train_sample_videos/dbhoxkblzx.mp4  \n",
            "  inflating: train_sample_videos/dbhrpizyeq.mp4  \n",
            "  inflating: train_sample_videos/dbnygxtwek.mp4  \n",
            "  inflating: train_sample_videos/dboxtiehng.mp4  \n",
            "  inflating: train_sample_videos/dbtbbhakdv.mp4  \n",
            "  inflating: train_sample_videos/dbzcqmxzaj.mp4  \n",
            "  inflating: train_sample_videos/dbzpcjntve.mp4  \n",
            "  inflating: train_sample_videos/dcamvmuors.mp4  \n",
            "  inflating: train_sample_videos/dcuiiorugd.mp4  \n",
            "  inflating: train_sample_videos/ddepeddixj.mp4  \n",
            "  inflating: train_sample_videos/ddhfabwpuz.mp4  \n",
            "  inflating: train_sample_videos/ddjggcasdw.mp4  \n",
            "  inflating: train_sample_videos/ddpvuimigj.mp4  \n",
            "  inflating: train_sample_videos/ddqccgmtka.mp4  \n",
            "  inflating: train_sample_videos/degpbqvcay.mp4  \n",
            "  inflating: train_sample_videos/deywhkarol.mp4  \n",
            "  inflating: train_sample_videos/deyyistcrd.mp4  \n",
            "  inflating: train_sample_videos/dfbpceeaox.mp4  \n",
            "  inflating: train_sample_videos/dgmevclvzy.mp4  \n",
            "  inflating: train_sample_videos/dgxrqjdomn.mp4  \n",
            "  inflating: train_sample_videos/dgzklxjmix.mp4  \n",
            "  inflating: train_sample_videos/dhcndnuwta.mp4  \n",
            "  inflating: train_sample_videos/dhcselezer.mp4  \n",
            "  inflating: train_sample_videos/dhevettufk.mp4  \n",
            "  inflating: train_sample_videos/dhjmzhrcav.mp4  \n",
            "  inflating: train_sample_videos/dhkwmjxwrn.mp4  \n",
            "  inflating: train_sample_videos/dhoqofwoxa.mp4  \n",
            "  inflating: train_sample_videos/dhxctgyoqj.mp4  \n",
            "  inflating: train_sample_videos/diomeixhrg.mp4  \n",
            "  inflating: train_sample_videos/diopzaywor.mp4  \n",
            "  inflating: train_sample_videos/diqraixiov.mp4  \n",
            "  inflating: train_sample_videos/diuzrpqjli.mp4  \n",
            "  inflating: train_sample_videos/djvtbgwdcc.mp4  \n",
            "  inflating: train_sample_videos/djvutyvaio.mp4  \n",
            "  inflating: train_sample_videos/djxdyjopjd.mp4  \n",
            "  inflating: train_sample_videos/dkdwxmtpuo.mp4  \n",
            "  inflating: train_sample_videos/dkhlttuvmx.mp4  \n",
            "  inflating: train_sample_videos/dkrvorliqc.mp4  \n",
            "  inflating: train_sample_videos/dkuayagnmc.mp4  \n",
            "  inflating: train_sample_videos/dkwjwbwgey.mp4  \n",
            "  inflating: train_sample_videos/dkzvdrzcnr.mp4  \n",
            "  inflating: train_sample_videos/dlpoieqvfb.mp4  \n",
            "  inflating: train_sample_videos/dlrsbscitn.mp4  \n",
            "  inflating: train_sample_videos/dnexlwbcxq.mp4  \n",
            "  inflating: train_sample_videos/dnhvalzvrt.mp4  \n",
            "  inflating: train_sample_videos/dntkzzzcdh.mp4  \n",
            "  inflating: train_sample_videos/dnyvfblxpm.mp4  \n",
            "  inflating: train_sample_videos/doanjploai.mp4  \n",
            "  inflating: train_sample_videos/dofusvhnib.mp4  \n",
            "  inflating: train_sample_videos/dozyddhild.mp4  \n",
            "  inflating: train_sample_videos/dptbnjnkdg.mp4  \n",
            "  inflating: train_sample_videos/dptrzdvwpg.mp4  \n",
            "  inflating: train_sample_videos/dqnyszdong.mp4  \n",
            "  inflating: train_sample_videos/dqppxmoqdl.mp4  \n",
            "  inflating: train_sample_videos/dqqtjcryjv.mp4  \n",
            "  inflating: train_sample_videos/dqswpjoepo.mp4  \n",
            "  inflating: train_sample_videos/dqzreruvje.mp4  \n",
            "  inflating: train_sample_videos/drcyabprvt.mp4  \n",
            "  inflating: train_sample_videos/drgjzlxzxj.mp4  \n",
            "  inflating: train_sample_videos/drsakwyvqv.mp4  \n",
            "  inflating: train_sample_videos/drtbksnpol.mp4  \n",
            "  inflating: train_sample_videos/dsdoseflas.mp4  \n",
            "  inflating: train_sample_videos/dsgpbgsrdm.mp4  \n",
            "  inflating: train_sample_videos/dsjbknkujw.mp4  \n",
            "  inflating: train_sample_videos/dsndhujjjb.mp4  \n",
            "  inflating: train_sample_videos/dtbpmdqvao.mp4  \n",
            "  inflating: train_sample_videos/dtocdfbwca.mp4  \n",
            "  inflating: train_sample_videos/dubiroskqn.mp4  \n",
            "  inflating: train_sample_videos/dulanfulol.mp4  \n",
            "  inflating: train_sample_videos/duvyaxbzvp.mp4  \n",
            "  inflating: train_sample_videos/duycddgtrl.mp4  \n",
            "  inflating: train_sample_videos/duzuusuajr.mp4  \n",
            "  inflating: train_sample_videos/dvakowbgbt.mp4  \n",
            "  inflating: train_sample_videos/dvumqqhoac.mp4  \n",
            "  inflating: train_sample_videos/dwediigjit.mp4  \n",
            "  inflating: train_sample_videos/dxbqjxrhin.mp4  \n",
            "  inflating: train_sample_videos/dxuliowugt.mp4  \n",
            "  inflating: train_sample_videos/dxuplhwvig.mp4  \n",
            "  inflating: train_sample_videos/dzieklokdr.mp4  \n",
            "  inflating: train_sample_videos/dzqwgqewhu.mp4  \n",
            "  inflating: train_sample_videos/dzvyfiarrq.mp4  \n",
            "  inflating: train_sample_videos/dzwkmcwkwl.mp4  \n",
            "  inflating: train_sample_videos/dzyuwjkjui.mp4  \n",
            "  inflating: train_sample_videos/eahlqmfvtj.mp4  \n",
            "  inflating: train_sample_videos/eajlrktemq.mp4  \n",
            "  inflating: train_sample_videos/ebchwmwayp.mp4  \n",
            "  inflating: train_sample_videos/ebebgmtlcu.mp4  \n",
            "  inflating: train_sample_videos/ebeknhudxq.mp4  \n",
            "  inflating: train_sample_videos/ebkzwjgjhq.mp4  \n",
            "  inflating: train_sample_videos/ebywfrmhtd.mp4  \n",
            "  inflating: train_sample_videos/eckvhdusax.mp4  \n",
            "  inflating: train_sample_videos/ecnihjlfyt.mp4  \n",
            "  inflating: train_sample_videos/ecujsjhscd.mp4  \n",
            "  inflating: train_sample_videos/ecuvtoltue.mp4  \n",
            "  inflating: train_sample_videos/ecwaxgutkc.mp4  \n",
            "  inflating: train_sample_videos/eczrseixwq.mp4  \n",
            "  inflating: train_sample_videos/edyncaijwx.mp4  \n",
            "  inflating: train_sample_videos/eebrkicpry.mp4  \n",
            "  inflating: train_sample_videos/eebserckhh.mp4  \n",
            "  inflating: train_sample_videos/eejswgycjc.mp4  \n",
            "  inflating: train_sample_videos/eekozbeafq.mp4  \n",
            "  inflating: train_sample_videos/eepezmygaq.mp4  \n",
            "  inflating: train_sample_videos/eeyhxisdfh.mp4  \n",
            "  inflating: train_sample_videos/efdyrflcpg.mp4  \n",
            "  inflating: train_sample_videos/efwfxwwlbw.mp4  \n",
            "  inflating: train_sample_videos/egbbcxcuqy.mp4  \n",
            "  inflating: train_sample_videos/eggbjzxnmg.mp4  \n",
            "  inflating: train_sample_videos/egghxjjmfg.mp4  \n",
            "  inflating: train_sample_videos/ehbnclaukr.mp4  \n",
            "  inflating: train_sample_videos/ehccixxzoe.mp4  \n",
            "  inflating: train_sample_videos/ehdkmxgtxh.mp4  \n",
            "  inflating: train_sample_videos/ehevsxtecd.mp4  \n",
            "  inflating: train_sample_videos/ehfiekigla.mp4  \n",
            "  inflating: train_sample_videos/ehieahnhte.mp4  \n",
            "  inflating: train_sample_videos/ehtdtkmmli.mp4  \n",
            "  inflating: train_sample_videos/eiriyukqqy.mp4  \n",
            "  inflating: train_sample_videos/eivxffliio.mp4  \n",
            "  inflating: train_sample_videos/eiwopxzjfn.mp4  \n",
            "  inflating: train_sample_videos/eixwxvxbbn.mp4  \n",
            "  inflating: train_sample_videos/ejkqesyvam.mp4  \n",
            "  inflating: train_sample_videos/ekcrtigpab.mp4  \n",
            "  inflating: train_sample_videos/ekhacizpah.mp4  \n",
            "  inflating: train_sample_videos/ekkdjkirzq.mp4  \n",
            "  inflating: train_sample_videos/elginszwtk.mp4  \n",
            "  inflating: train_sample_videos/ellavthztb.mp4  \n",
            "  inflating: train_sample_videos/elvvackpjh.mp4  \n",
            "  inflating: train_sample_videos/emaalmsonj.mp4  \n",
            "  inflating: train_sample_videos/emfbhytfhc.mp4  \n",
            "  inflating: train_sample_videos/emgjphonqb.mp4  \n",
            "  inflating: train_sample_videos/ensyyivobf.mp4  \n",
            "  inflating: train_sample_videos/eoewqcpbgt.mp4  \n",
            "  inflating: train_sample_videos/eprybmbpba.mp4  \n",
            "  inflating: train_sample_videos/epymyyiblu.mp4  \n",
            "  inflating: train_sample_videos/eqjscdagiv.mp4  \n",
            "  inflating: train_sample_videos/eqnoqyfquo.mp4  \n",
            "  inflating: train_sample_videos/eqvuznuwsa.mp4  \n",
            "  inflating: train_sample_videos/erlvuvjsjf.mp4  \n",
            "  inflating: train_sample_videos/erqgqacbqe.mp4  \n",
            "  inflating: train_sample_videos/errocgcham.mp4  \n",
            "  inflating: train_sample_videos/esckbnkkvb.mp4  \n",
            "  inflating: train_sample_videos/esgftaficx.mp4  \n",
            "  inflating: train_sample_videos/esnntzzajv.mp4  \n",
            "  inflating: train_sample_videos/esxrvsgpvb.mp4  \n",
            "  inflating: train_sample_videos/esyhwdfnxs.mp4  \n",
            "  inflating: train_sample_videos/esyrimvzsa.mp4  \n",
            "  inflating: train_sample_videos/etdcqxabww.mp4  \n",
            "  inflating: train_sample_videos/etejaapnxh.mp4  \n",
            "  inflating: train_sample_videos/etmcruaihe.mp4  \n",
            "  inflating: train_sample_videos/etohcvnzbj.mp4  \n",
            "  inflating: train_sample_videos/eudeqjhdfd.mp4  \n",
            "  inflating: train_sample_videos/eukvucdetx.mp4  \n",
            "  inflating: train_sample_videos/metadata.json  \n"
          ]
        }
      ],
      "source": [
        "!!kaggle competitions download -c deepfake-detection-challenge\n",
        "\n",
        "!unzip deepfake-detection-challenge.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KCBq_Svm5LfF",
        "outputId": "9754ea50-8bb5-4124-f6bb-0404fccb605e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Copied abarnvbtwb.mp4 to selected_videos\n",
            "Copied aelfnikyqj.mp4 to selected_videos\n",
            "Copied afoovlsmtx.mp4 to selected_videos\n",
            "Copied agrmhtjdlk.mp4 to selected_videos\n",
            "Copied ahqqqilsxt.mp4 to selected_videos\n",
            "Copied aagfhgtpmv.mp4 to selected_videos\n",
            "Copied aapnvogymq.mp4 to selected_videos\n",
            "Copied abofeumbvv.mp4 to selected_videos\n",
            "Copied abqwwspghj.mp4 to selected_videos\n",
            "Copied acifjvzvpm.mp4 to selected_videos\n"
          ]
        }
      ],
      "source": [
        "import shutil\n",
        "import os\n",
        "import json\n",
        "\n",
        "def filter_and_copy_videos(metadata, source_dir, target_dir, num_real=5, num_fake=5):\n",
        "    # Create target directory if it does not exist\n",
        "    if not os.path.exists(target_dir):\n",
        "        os.makedirs(target_dir)\n",
        "\n",
        "    # Extract real and fake video filenames from metadata\n",
        "    real_videos = [video for video, info in metadata.items() if info['label'] == 'REAL']\n",
        "    fake_videos = [video for video, info in metadata.items() if info['label'] == 'FAKE']\n",
        "\n",
        "    # Select the desired number of videos\n",
        "    selected_real_videos = real_videos[:num_real]\n",
        "    selected_fake_videos = fake_videos[:num_fake]\n",
        "\n",
        "    # Combine selected videos\n",
        "    all_selected_videos = selected_real_videos + selected_fake_videos\n",
        "\n",
        "    # Copy selected videos to the target directory\n",
        "    for video in all_selected_videos:\n",
        "        src = os.path.join(source_dir, video)\n",
        "        dst = os.path.join(target_dir, video)\n",
        "        if os.path.exists(src):\n",
        "            shutil.copy(src, dst)\n",
        "            print(f\"Copied {video} to {target_dir}\")\n",
        "        else:\n",
        "            print(f\"Video not found: {src}\")\n",
        "\n",
        "# Load metadata.json\n",
        "with open('train_sample_videos/metadata.json', 'r') as f:\n",
        "    metadata = json.load(f)\n",
        "\n",
        "# Define directories\n",
        "source_dir = 'train_sample_videos'\n",
        "target_dir = 'selected_videos'\n",
        "\n",
        "# Filter and copy videos\n",
        "filter_and_copy_videos(metadata, source_dir, target_dir)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DhWIdXNg5Pxc",
        "outputId": "6515a478-bd45-4d66-b261-9f09412e4132"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files moved to Google Drive successfully.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "\n",
        "# Define source and target directories\n",
        "source_dir = '/content/selected_videos'  # Update this to your Colab directory\n",
        "target_dir = '/content/drive/MyDrive/10videos'  # Update this to your Google Drive directory\n",
        "\n",
        "# Create the target directory in Google Drive if it doesn't exist\n",
        "os.makedirs(target_dir, exist_ok=True)\n",
        "\n",
        "# Move files from Colab environment to Google Drive\n",
        "for filename in os.listdir(source_dir):\n",
        "    src_path = os.path.join(source_dir, filename)\n",
        "    dst_path = os.path.join(target_dir, filename)\n",
        "    shutil.move(src_path, dst_path)\n",
        "\n",
        "print(\"Files moved to Google Drive successfully.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rn9t8drq8q-g",
        "outputId": "92206047-140b-4e17-da4e-43fa46dc6952"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Copied abarnvbtwb.mp4 to /content/selected_videos\n",
            "Copied aelfnikyqj.mp4 to /content/selected_videos\n",
            "Copied afoovlsmtx.mp4 to /content/selected_videos\n",
            "Copied agrmhtjdlk.mp4 to /content/selected_videos\n",
            "Copied ahqqqilsxt.mp4 to /content/selected_videos\n",
            "Copied aagfhgtpmv.mp4 to /content/selected_videos\n",
            "Copied aapnvogymq.mp4 to /content/selected_videos\n",
            "Copied abofeumbvv.mp4 to /content/selected_videos\n",
            "Copied abqwwspghj.mp4 to /content/selected_videos\n",
            "Copied acifjvzvpm.mp4 to /content/selected_videos\n",
            "Moved aelfnikyqj.mp4 to /content/drive/MyDrive/train_sample_videos/selected_real_videos/aelfnikyqj.mp4\n",
            "Moved aapnvogymq.mp4 to /content/drive/MyDrive/train_sample_videos/selected_fake_videos/aapnvogymq.mp4\n",
            "Moved ahqqqilsxt.mp4 to /content/drive/MyDrive/train_sample_videos/selected_real_videos/ahqqqilsxt.mp4\n",
            "Moved abarnvbtwb.mp4 to /content/drive/MyDrive/train_sample_videos/selected_real_videos/abarnvbtwb.mp4\n",
            "Moved agrmhtjdlk.mp4 to /content/drive/MyDrive/train_sample_videos/selected_real_videos/agrmhtjdlk.mp4\n",
            "Moved abqwwspghj.mp4 to /content/drive/MyDrive/train_sample_videos/selected_fake_videos/abqwwspghj.mp4\n",
            "Moved aagfhgtpmv.mp4 to /content/drive/MyDrive/train_sample_videos/selected_fake_videos/aagfhgtpmv.mp4\n",
            "Moved abofeumbvv.mp4 to /content/drive/MyDrive/train_sample_videos/selected_fake_videos/abofeumbvv.mp4\n",
            "Moved afoovlsmtx.mp4 to /content/drive/MyDrive/train_sample_videos/selected_real_videos/afoovlsmtx.mp4\n",
            "Moved acifjvzvpm.mp4 to /content/drive/MyDrive/train_sample_videos/selected_fake_videos/acifjvzvpm.mp4\n",
            "Videos separated and moved to Google Drive successfully.\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import json\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define directories\n",
        "base_dir = '/content/drive/MyDrive/train_sample_videos'\n",
        "source_dir = '/content/selected_videos'\n",
        "selected_real_videos_dir = os.path.join(base_dir, 'selected_real_videos')\n",
        "selected_fake_videos_dir = os.path.join(base_dir, 'selected_fake_videos')\n",
        "\n",
        "# Load metadata.json\n",
        "with open('/content/train_sample_videos/metadata.json', 'r') as f:\n",
        "    metadata = json.load(f)\n",
        "\n",
        "def filter_and_copy_videos(metadata, source_dir, num_real=5, num_fake=5):\n",
        "    # Create target directory if it does not exist\n",
        "    if not os.path.exists(source_dir):\n",
        "        os.makedirs(source_dir)\n",
        "\n",
        "    # Extract real and fake video filenames from metadata\n",
        "    real_videos = [video for video, info in metadata.items() if info['label'] == 'REAL']\n",
        "    fake_videos = [video for video, info in metadata.items() if info['label'] == 'FAKE']\n",
        "\n",
        "    # Select the desired number of videos\n",
        "    selected_real_videos = real_videos[:num_real]\n",
        "    selected_fake_videos = fake_videos[:num_fake]\n",
        "\n",
        "    # Combine selected videos\n",
        "    all_selected_videos = selected_real_videos + selected_fake_videos\n",
        "\n",
        "    # Copy selected videos to the target directory\n",
        "    for video in all_selected_videos:\n",
        "        src = os.path.join('train_sample_videos', video)\n",
        "        dst = os.path.join(source_dir, video)\n",
        "        if os.path.exists(src):\n",
        "            shutil.copy(src, dst)\n",
        "            print(f\"Copied {video} to {source_dir}\")\n",
        "        else:\n",
        "            print(f\"Video not found: {src}\")\n",
        "\n",
        "# Filter and copy videos\n",
        "filter_and_copy_videos(metadata, source_dir)\n",
        "\n",
        "# Create directories in Google Drive for real and fake videos\n",
        "os.makedirs(selected_real_videos_dir, exist_ok=True)\n",
        "os.makedirs(selected_fake_videos_dir, exist_ok=True)\n",
        "\n",
        "# Separate the copied videos into real and fake directories\n",
        "for filename in os.listdir(source_dir):\n",
        "    src_path = os.path.join(source_dir, filename)\n",
        "    if filename in metadata:\n",
        "        label = metadata[filename]['label']\n",
        "        if label == 'REAL':\n",
        "            dst_path = os.path.join(selected_real_videos_dir, filename)\n",
        "        elif label == 'FAKE':\n",
        "            dst_path = os.path.join(selected_fake_videos_dir, filename)\n",
        "        else:\n",
        "            print(f\"Unknown label for {filename}: {label}\")\n",
        "            continue\n",
        "        shutil.move(src_path, dst_path)\n",
        "        print(f\"Moved {filename} to {dst_path}\")\n",
        "\n",
        "print(\"Videos separated and moved to Google Drive successfully.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "id": "pCcF-zVR9LSv",
        "outputId": "0abe5658-0539-4273-f606-6999264cd579"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Frames extracted and saved to /content/drive/MyDrive/train_sample_videos/frames_real_videos/aelfnikyqj\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-a7b7a0e21eab>\u001b[0m in \u001b[0;36m<cell line: 34>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mframes_output_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframes_real_videos_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframes_output_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Create directory for each video's frames\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0mextract_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframes_output_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;31m# Extract frames from fake videos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-a7b7a0e21eab>\u001b[0m in \u001b[0;36mextract_frames\u001b[0;34m(video_path, frames_output_dir)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mframe_filename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframes_output_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"frame_{count:04d}.jpg\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m             \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe_filename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Save frame as JPEG file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvidcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mcount\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import os\n",
        "import cv2\n",
        "\n",
        "# Define directories for frames\n",
        "frames_real_videos_dir = os.path.join(base_dir, 'frames_real_videos')\n",
        "frames_fake_videos_dir = os.path.join(base_dir, 'frames_fake_videos')\n",
        "\n",
        "# Create directories for frames in Google Drive\n",
        "os.makedirs(frames_real_videos_dir, exist_ok=True)\n",
        "os.makedirs(frames_fake_videos_dir, exist_ok=True)\n",
        "\n",
        "def extract_frames(video_path, frames_output_dir):\n",
        "    \"\"\"\n",
        "    Extracts frames from a video and saves them to the specified directory.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        vidcap = cv2.VideoCapture(video_path)\n",
        "        if not vidcap.isOpened():\n",
        "            print(f\"Error: Unable to open video file {video_path}\")\n",
        "            return\n",
        "        count = 0\n",
        "        success, image = vidcap.read()\n",
        "        while success:\n",
        "            frame_filename = os.path.join(frames_output_dir, f\"frame_{count:04d}.jpg\")\n",
        "            cv2.imwrite(frame_filename, image)  # Save frame as JPEG file\n",
        "            success, image = vidcap.read()\n",
        "            count += 1\n",
        "        vidcap.release()\n",
        "        print(f\"Frames extracted and saved to {frames_output_dir}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error extracting frames from {video_path}: {e}\")\n",
        "\n",
        "# Extract frames from real videos\n",
        "for filename in os.listdir(selected_real_videos_dir):\n",
        "    video_path = os.path.join(selected_real_videos_dir, filename)\n",
        "    frames_output_dir = os.path.join(frames_real_videos_dir, os.path.splitext(filename)[0])\n",
        "    os.makedirs(frames_output_dir, exist_ok=True)  # Create directory for each video's frames\n",
        "    extract_frames(video_path, frames_output_dir)\n",
        "\n",
        "# Extract frames from fake videos\n",
        "for filename in os.listdir(selected_fake_videos_dir):\n",
        "    video_path = os.path.join(selected_fake_videos_dir, filename)\n",
        "    frames_output_dir = os.path.join(frames_fake_videos_dir, os.path.splitext(filename)[0])\n",
        "    os.makedirs(frames_output_dir, exist_ok=True)  # Create directory for each video's frames\n",
        "    extract_frames(video_path, frames_output_dir)\n",
        "\n",
        "print(\"Frame extraction completed and saved to Google Drive.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S6fY22g89ylI"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# Define directories for frames\n",
        "frames_real_videos_dir = '/content/drive/MyDrive/train_sample_videos/frames_real_videos'\n",
        "frames_fake_videos_dir = '/content/drive/MyDrive/train_sample_videos/frames_fake_videos'\n",
        "\n",
        "# Define a directory to save preprocessed frames\n",
        "preprocessed_real_videos_dir = '/content/drive/MyDrive/train_sample_videos/preprocessed_real_videos'\n",
        "preprocessed_fake_videos_dir = '/content/drive/MyDrive/train_sample_videos/preprocessed_fake_videos'\n",
        "\n",
        "# Create directories for preprocessed frames\n",
        "os.makedirs(preprocessed_real_videos_dir, exist_ok=True)\n",
        "os.makedirs(preprocessed_fake_videos_dir, exist_ok=True)\n",
        "\n",
        "def preprocess_frame(frame):\n",
        "    \"\"\"\n",
        "    Preprocesses a single frame. This example includes resizing and normalization.\n",
        "    Modify this function according to your preprocessing needs.\n",
        "    \"\"\"\n",
        "    # Resize frame to 224x224 (example size, adjust as needed)\n",
        "    frame = cv2.resize(frame, (224, 224))\n",
        "\n",
        "    # Normalize frame to [0, 1]\n",
        "    frame = frame / 255.0\n",
        "\n",
        "    return frame\n",
        "\n",
        "def process_frames(frames_dir, preprocessed_dir):\n",
        "    \"\"\"\n",
        "    Processes frames from the given directory and saves preprocessed frames.\n",
        "    \"\"\"\n",
        "    for video_folder in os.listdir(frames_dir):\n",
        "        video_frames_dir = os.path.join(frames_dir, video_folder)\n",
        "        preprocessed_video_frames_dir = os.path.join(preprocessed_dir, video_folder)\n",
        "        os.makedirs(preprocessed_video_frames_dir, exist_ok=True)\n",
        "\n",
        "        for frame_file in os.listdir(video_frames_dir):\n",
        "            frame_path = os.path.join(video_frames_dir, frame_file)\n",
        "            # Read the frame\n",
        "            frame = cv2.imread(frame_path)\n",
        "            if frame is not None:\n",
        "                # Preprocess the frame\n",
        "                preprocessed_frame = preprocess_frame(frame)\n",
        "                # Save the preprocessed frame\n",
        "                preprocessed_frame_path = os.path.join(preprocessed_video_frames_dir, frame_file)\n",
        "                cv2.imwrite(preprocessed_frame_path, (preprocessed_frame * 255).astype(np.uint8))  # Convert back to [0, 255]\n",
        "\n",
        "# Process and preprocess frames for real and fake videos\n",
        "process_frames(frames_real_videos_dir, preprocessed_real_videos_dir)\n",
        "process_frames(frames_fake_videos_dir, preprocessed_fake_videos_dir)\n",
        "\n",
        "print(\"Frame preprocessing completed and saved to Google Drive.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eRxJtwQW-_m9",
        "outputId": "f67b8413-16a6-4a73-c769-02e4dd9abd55"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Preprocessed frames copied to Colab environment.\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define directories in Google Drive and Colab environment\n",
        "preprocessed_real_videos_dir = '/content/drive/MyDrive/train_sample_videos/preprocessed_real_videos'\n",
        "preprocessed_fake_videos_dir = '/content/drive/MyDrive/train_sample_videos/preprocessed_fake_videos'\n",
        "colab_real_videos_dir = '/content/preprocessed_real_videos'\n",
        "colab_fake_videos_dir = '/content/preprocessed_fake_videos'\n",
        "\n",
        "# Create directories in Colab\n",
        "os.makedirs(colab_real_videos_dir, exist_ok=True)\n",
        "os.makedirs(colab_fake_videos_dir, exist_ok=True)\n",
        "\n",
        "# Copy preprocessed frames from Google Drive to Colab\n",
        "shutil.copytree(preprocessed_real_videos_dir, colab_real_videos_dir, dirs_exist_ok=True)\n",
        "shutil.copytree(preprocessed_fake_videos_dir, colab_fake_videos_dir, dirs_exist_ok=True)\n",
        "\n",
        "print(\"Preprocessed frames copied to Colab environment.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Iv2Q1-4OBsqI"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, real_dir, fake_dir, transform=None):\n",
        "        self.real_dir = real_dir\n",
        "\n",
        "        self.fake_dir = fake_dir\n",
        "        self.transform = transform\n",
        "\n",
        "        self.real_images = self._load_images(self.real_dir)\n",
        "        self.fake_images = self._load_images(self.fake_dir)\n",
        "\n",
        "        self.all_images = self.real_images + self.fake_images\n",
        "        self.labels = [1] * len(self.real_images) + [0] * len(self.fake_images)\n",
        "\n",
        "    def _load_images(self, dir_path):\n",
        "        images = []\n",
        "        for subdir, _, files in os.walk(dir_path):\n",
        "            for file in files:\n",
        "                file_path = os.path.join(subdir, file)\n",
        "                try:\n",
        "                    img = Image.open(file_path).convert('RGB')\n",
        "                    images.append(img)\n",
        "                except Exception as e:\n",
        "                    print(f\"Error loading image {file_path}: {e}\")\n",
        "        return images\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.all_images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img = self.all_images[idx]\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        return img, label\n",
        "\n",
        "# Define transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((64, 64)),  # Resize to fit the GAN's input size\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "# Instantiate dataset and dataloader\n",
        "dataset = CustomDataset(preprocessed_real_videos_dir, preprocessed_fake_videos_dir, transform=transform)\n",
        "dataloader = DataLoader(dataset, batch_size=64, shuffle=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "# Generator Network\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, input_dim, label_dim):\n",
        "        super(Generator, self).__init__()\n",
        "        self.label_dim = label_dim\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(input_dim + label_dim, 256),\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 512),\n",
        "            nn.BatchNorm1d(512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 1024),\n",
        "            nn.BatchNorm1d(1024),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(1024, 64*64*3),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, noise, labels):\n",
        "        input = torch.cat((noise, labels), dim=1)\n",
        "        output = self.model(input)\n",
        "        output = output.view(-1, 3, 64, 64)\n",
        "        return output\n",
        "\n",
        "# Discriminator Network\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, label_dim):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.label_dim = label_dim\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Linear(64*64*3 + label_dim, 512),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(256, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "        self.feature_layer = nn.Sequential(\n",
        "            nn.Linear(64*64*3 + label_dim, 512),\n",
        "            nn.LeakyReLU(0.2)\n",
        "        )\n",
        "\n",
        "    def forward(self, imgs, labels):\n",
        "        imgs_flat = imgs.view(imgs.size(0), -1)\n",
        "        input = torch.cat((imgs_flat, labels), dim=1)\n",
        "        features = self.feature_layer(input)\n",
        "        output = self.features(input)\n",
        "        return output, features\n"
      ],
      "metadata": {
        "id": "r14lNGNC-H_5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from torch.utils.data\n",
        "import DataLoader\n",
        "\n",
        "def train_cgan(generator, discriminator, dataloader, epochs=100, lr=0.0002, beta1=0.5, beta2=0.999, feature_csv='features.csv'):\n",
        "  device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "  generator.to(device)\n",
        "  discriminator.to(device)\n",
        "\n",
        "# Define loss function and optimizers\n",
        "criterion = nn.BCELoss()\n",
        "optimizer_g = optim.Adam(generator.parameters(), lr=lr, betas=(beta1, beta2))\n",
        "optimizer_d = optim.Adam(discriminator.parameters(), lr=lr, betas=(beta1, beta2))\n",
        "\n",
        "feature_list = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    d_loss_real_total = 0\n",
        "    d_loss_fake_total = 0\n",
        "    g_loss_total = 0\n",
        "    correct_preds = 0\n",
        "    total_preds = 0\n",
        "\n",
        "    for imgs, labels in dataloader:\n",
        "        batch_size = imgs.size(0)\n",
        "        real_labels = torch.ones(batch_size, 1).to(device)\n",
        "        fake_labels = torch.zeros(batch_size, 1).to(device)\n",
        "        labels = labels.float().unsqueeze(1).to(device)\n",
        "\n",
        "        # Train Discriminator\n",
        "        optimizer_d.zero_grad()\n",
        "\n",
        "        outputs, _ = discriminator(imgs.to(device), labels)\n",
        "        d_loss_real = criterion(outputs, real_labels)\n",
        "        d_loss_real.backward()\n",
        "\n",
        "        noise = torch.randn(batch_size, 100, device=device)\n",
        "        fake_imgs = generator(noise, labels)\n",
        "        outputs, _ = discriminator(fake_imgs.detach(), fake_labels)\n",
        "        d_loss_fake = criterion(outputs, fake_labels)\n",
        "        d_loss_fake.backward()\n",
        "\n",
        "        d_loss = d_loss_real + d_loss_fake\n",
        "        optimizer_d.step()\n",
        "\n",
        "        d_loss_real_total += d_loss_real.item()\n",
        "        d_loss_fake_total += d_loss_fake.item()\n",
        "\n",
        "        # Track discriminator accuracy\n",
        "        preds = (outputs > 0.5).float()\n",
        "        correct_preds += (preds == real_labels).sum().item()\n",
        "        total_preds += real_labels.size(0)\n",
        "\n",
        "        # Train Generator\n",
        "        optimizer_g.zero_grad()\n",
        "\n",
        "        outputs, _ = discriminator(fake_imgs, real_labels)\n",
        "        g_loss = criterion(outputs, real_labels)\n",
        "        g_loss.backward()\n",
        "\n",
        "        optimizer_g.step()\n",
        "\n",
        "        g_loss_total += g_loss.item()\n",
        "\n",
        "    # Calculate average losses and accuracy\n",
        "    avg_d_loss_real = d_loss_real_total / len(dataloader)\n",
        "    avg_d_loss_fake = d_loss_fake_total / len(dataloader)\n",
        "    avg_d_loss = (avg_d_loss_real + avg_d_loss_fake) / 2\n",
        "    avg_g_loss = g_loss_total / len(dataloader)\n",
        "    accuracy = (correct_preds / total_preds) * 100\n",
        "\n",
        "    print(f'Epoch [{epoch+1}/{epochs}] | D Loss: {avg_d_loss:.4f} | G Loss: {avg_g_loss:.4f} | Accuracy: {accuracy:.2f}%')\n",
        "\n",
        "# Save features to CSV\n",
        "## This is formatted as code\n",
        "all_features = np.vstack([item[0] for item in feature_list])\n",
        "all_labels = np.hstack([item[1] for item in feature_list])\n",
        "df = pd.DataFrame(all_features)\n",
        "df['label'] = all_labels\n",
        "df.to_csv(feature_csv, index=False)"
      ],
      "metadata": {
        "id": "CR3RZrQKRZKI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_c3gvZXqrwv8"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import h5py\n",
        "\n",
        "def csv_to_h5(csv_file, h5_file='features.h5'):\n",
        "    # Load the CSV file into a pandas DataFrame\n",
        "    df = pd.read_csv(csv_file)\n",
        "\n",
        "    # Open an HDF5 file\n",
        "    with h5py.File(h5_file, 'w') as hf:\n",
        "        # Convert DataFrame to numpy array and save as a dataset\n",
        "        hf.create_dataset('data', data=df.to_numpy())\n",
        "        # Save column names as an attribute\n",
        "        hf.attrs['columns'] = df.columns.tolist()\n",
        "\n",
        "# Example usage\n",
        "csv_file = '/content/features.csv'\n",
        "csv_to_h5(csv_file)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Zi3Ug6y0rv9",
        "outputId": "178a7eae-fa55-434f-b9d4-18035b899c86"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data:\n",
            "[[-0.00273751  0.4100715  -0.08643369 ... -0.08144077  0.05586879\n",
            "   1.        ]\n",
            " [ 0.23171264  0.5903702  -0.06884621 ...  0.0779786   0.10680581\n",
            "   1.        ]\n",
            " [-0.01618372  0.5060589  -0.0335055  ... -0.05537903 -0.00718816\n",
            "   1.        ]\n",
            " ...\n",
            " [ 0.17301129  0.40487516  0.08902231 ...  0.5762343  -0.03750245\n",
            "   0.        ]\n",
            " [ 0.1464526   0.3763593   0.08456452 ...  0.5511196  -0.03610711\n",
            "   0.        ]\n",
            " [ 0.1800172   0.4234184   0.08917844 ...  0.59344757 -0.03668004\n",
            "   0.        ]]\n",
            "Columns:\n",
            "['0' '1' '2' '3' '4' '5' '6' '7' '8' '9' '10' '11' '12' '13' '14' '15'\n",
            " '16' '17' '18' '19' '20' '21' '22' '23' '24' '25' '26' '27' '28' '29'\n",
            " '30' '31' '32' '33' '34' '35' '36' '37' '38' '39' '40' '41' '42' '43'\n",
            " '44' '45' '46' '47' '48' '49' '50' '51' '52' '53' '54' '55' '56' '57'\n",
            " '58' '59' '60' '61' '62' '63' '64' '65' '66' '67' '68' '69' '70' '71'\n",
            " '72' '73' '74' '75' '76' '77' '78' '79' '80' '81' '82' '83' '84' '85'\n",
            " '86' '87' '88' '89' '90' '91' '92' '93' '94' '95' '96' '97' '98' '99'\n",
            " '100' '101' '102' '103' '104' '105' '106' '107' '108' '109' '110' '111'\n",
            " '112' '113' '114' '115' '116' '117' '118' '119' '120' '121' '122' '123'\n",
            " '124' '125' '126' '127' '128' '129' '130' '131' '132' '133' '134' '135'\n",
            " '136' '137' '138' '139' '140' '141' '142' '143' '144' '145' '146' '147'\n",
            " '148' '149' '150' '151' '152' '153' '154' '155' '156' '157' '158' '159'\n",
            " '160' '161' '162' '163' '164' '165' '166' '167' '168' '169' '170' '171'\n",
            " '172' '173' '174' '175' '176' '177' '178' '179' '180' '181' '182' '183'\n",
            " '184' '185' '186' '187' '188' '189' '190' '191' '192' '193' '194' '195'\n",
            " '196' '197' '198' '199' '200' '201' '202' '203' '204' '205' '206' '207'\n",
            " '208' '209' '210' '211' '212' '213' '214' '215' '216' '217' '218' '219'\n",
            " '220' '221' '222' '223' '224' '225' '226' '227' '228' '229' '230' '231'\n",
            " '232' '233' '234' '235' '236' '237' '238' '239' '240' '241' '242' '243'\n",
            " '244' '245' '246' '247' '248' '249' '250' '251' '252' '253' '254' '255'\n",
            " '256' '257' '258' '259' '260' '261' '262' '263' '264' '265' '266' '267'\n",
            " '268' '269' '270' '271' '272' '273' '274' '275' '276' '277' '278' '279'\n",
            " '280' '281' '282' '283' '284' '285' '286' '287' '288' '289' '290' '291'\n",
            " '292' '293' '294' '295' '296' '297' '298' '299' '300' '301' '302' '303'\n",
            " '304' '305' '306' '307' '308' '309' '310' '311' '312' '313' '314' '315'\n",
            " '316' '317' '318' '319' '320' '321' '322' '323' '324' '325' '326' '327'\n",
            " '328' '329' '330' '331' '332' '333' '334' '335' '336' '337' '338' '339'\n",
            " '340' '341' '342' '343' '344' '345' '346' '347' '348' '349' '350' '351'\n",
            " '352' '353' '354' '355' '356' '357' '358' '359' '360' '361' '362' '363'\n",
            " '364' '365' '366' '367' '368' '369' '370' '371' '372' '373' '374' '375'\n",
            " '376' '377' '378' '379' '380' '381' '382' '383' '384' '385' '386' '387'\n",
            " '388' '389' '390' '391' '392' '393' '394' '395' '396' '397' '398' '399'\n",
            " '400' '401' '402' '403' '404' '405' '406' '407' '408' '409' '410' '411'\n",
            " '412' '413' '414' '415' '416' '417' '418' '419' '420' '421' '422' '423'\n",
            " '424' '425' '426' '427' '428' '429' '430' '431' '432' '433' '434' '435'\n",
            " '436' '437' '438' '439' '440' '441' '442' '443' '444' '445' '446' '447'\n",
            " '448' '449' '450' '451' '452' '453' '454' '455' '456' '457' '458' '459'\n",
            " '460' '461' '462' '463' '464' '465' '466' '467' '468' '469' '470' '471'\n",
            " '472' '473' '474' '475' '476' '477' '478' '479' '480' '481' '482' '483'\n",
            " '484' '485' '486' '487' '488' '489' '490' '491' '492' '493' '494' '495'\n",
            " '496' '497' '498' '499' '500' '501' '502' '503' '504' '505' '506' '507'\n",
            " '508' '509' '510' '511' 'label']\n"
          ]
        }
      ],
      "source": [
        "import h5py\n",
        "\n",
        "def read_h5(h5_file='features.h5'):\n",
        "    try:\n",
        "        # Open an HDF5 file for reading\n",
        "        with h5py.File(h5_file, 'r') as hf:\n",
        "            # Access the dataset\n",
        "            if 'data' in hf:\n",
        "                data = hf['data'][:]\n",
        "            else:\n",
        "                raise KeyError(\"'data' dataset not found in the file.\")\n",
        "\n",
        "            # Access the attributes\n",
        "            if 'columns' in hf.attrs:\n",
        "                columns = hf.attrs['columns']\n",
        "            else:\n",
        "                raise KeyError(\"'columns' attribute not found in the file.\")\n",
        "\n",
        "            return data, columns\n",
        "\n",
        "    except KeyError as e:\n",
        "        print(f\"Error: {e}\")\n",
        "        print(f\"The specified object does not exist in the file: {h5_file}\")\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "\n",
        "# Example usage\n",
        "data, columns = read_h5()\n",
        "print(\"Data:\")\n",
        "print(data)\n",
        "print(\"Columns:\")\n",
        "print(columns)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import os\n",
        "import h5py\n",
        "from PIL import Image\n",
        "from torchvision import transforms, models\n",
        "import torch.nn as nn\n",
        "\n",
        "# Define preprocessing transforms\n",
        "preprocess = transforms.Compose([\n",
        "    transforms.Resize((112, 112)),  # Adjust to match the model's input size\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "def load_frames_from_directory(directory_path, num_frames=16):\n",
        "    all_frames = []\n",
        "    video_files = sorted(os.listdir(directory_path))  # Ensure consistent ordering\n",
        "    for video_file in video_files:\n",
        "        video_path = os.path.join(directory_path, video_file)\n",
        "        frames = []\n",
        "        for img_file in sorted(os.listdir(video_path)):  # Assuming frames are in subdirectories\n",
        "            img_path = os.path.join(video_path, img_file)\n",
        "            frame = Image.open(img_path).convert('RGB')  # Ensure 3 channels (RGB)\n",
        "            frame = preprocess(frame)  # Apply preprocessing\n",
        "            frames.append(frame)\n",
        "            if len(frames) >= num_frames:\n",
        "                break\n",
        "\n",
        "        if len(frames) == num_frames:\n",
        "            all_frames.append(torch.stack(frames))  # Shape: [num_frames, C, H, W]\n",
        "        else:\n",
        "            print(f\"Not enough frames found in directory: {video_path}\")\n",
        "\n",
        "    return all_frames\n",
        "\n",
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, num_layers, output_dim):\n",
        "        super(LSTMModel, self).__init__()\n",
        "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: [batch_size, seq_length, input_dim]\n",
        "        lstm_out, (hn, cn) = self.lstm(x)\n",
        "        # Use the output from the last time step\n",
        "        last_time_step_out = lstm_out[:, -1, :]  # Take the output from the last time step\n",
        "        output = self.fc(last_time_step_out)\n",
        "        return output\n",
        "\n",
        "def preprocess_frames(frames, feature_extractor):\n",
        "    features = []\n",
        "    for frame in frames:\n",
        "        frame = frame.unsqueeze(0)  # Add batch dimension\n",
        "        with torch.no_grad():\n",
        "            feature = feature_extractor(frame).squeeze()  # Extract features\n",
        "        features.append(feature)\n",
        "    return torch.stack(features)  # Shape: [num_frames, num_features]\n",
        "\n",
        "def extract_temporal_features(real_dir, fake_dir, feature_extractor, model):\n",
        "    all_features = []\n",
        "    all_labels = []\n",
        "\n",
        "    # Extract features from real videos\n",
        "    real_frames = load_frames_from_directory(real_dir)\n",
        "    for frames in real_frames:\n",
        "        features = preprocess_frames(frames, feature_extractor)\n",
        "        features_tensor = features.unsqueeze(0).to(device)  # Shape: [1, num_frames, num_features]\n",
        "        with torch.no_grad():\n",
        "            output = model(features_tensor).cpu().numpy()\n",
        "            all_features.append(output.flatten())\n",
        "            all_labels.append(1)  # Label for real videos\n",
        "\n",
        "    # Extract features from fake videos\n",
        "    fake_frames = load_frames_from_directory(fake_dir)\n",
        "    for frames in fake_frames:\n",
        "        features = preprocess_frames(frames, feature_extractor)\n",
        "        features_tensor = features.unsqueeze(0).to(device)  # Shape: [1, num_frames, num_features]\n",
        "        with torch.no_grad():\n",
        "            output = model(features_tensor).cpu().numpy()\n",
        "            all_features.append(output.flatten())\n",
        "            all_labels.append(0)  # Label for fake videos\n",
        "\n",
        "    if len(all_features) == 0:\n",
        "        raise ValueError(\"No features extracted. Check the input directories and video frames.\")\n",
        "\n",
        "    return np.array(all_features), np.array(all_labels)\n",
        "\n",
        "def save_features_to_hdf5(features, labels, hdf5_file):\n",
        "    with h5py.File(hdf5_file, 'w') as hf:\n",
        "        hf.create_dataset('features', data=features)\n",
        "        hf.create_dataset('labels', data=labels)\n",
        "\n",
        "# Define directories\n",
        "real_video_dir = '/content/preprocessed_real_videos'\n",
        "fake_video_dir = '/content/preprocessed_fake_videos'\n",
        "\n",
        "# Define dimensions\n",
        "input_dim = 2048  # Example: Flattened features from a CNN\n",
        "hidden_dim = 512\n",
        "num_layers = 2\n",
        "output_dim = 1\n",
        "\n",
        "# Instantiate feature extractor (e.g., a pre-trained CNN like ResNet)\n",
        "feature_extractor = models.resnet50(pretrained=True)\n",
        "feature_extractor.fc = nn.Identity()  # Remove the final classification layer\n",
        "\n",
        "# Instantiate the LSTM model\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "feature_extractor = feature_extractor.to(device)\n",
        "lstm_model = LSTMModel(input_dim, hidden_dim, num_layers, output_dim).to(device)\n",
        "\n",
        "# Extract features and save them\n",
        "features, labels = extract_temporal_features(real_video_dir, fake_video_dir, feature_extractor, lstm_model)\n",
        "save_features_to_hdf5(features, labels, 'temporal_features.h5')\n",
        "print(\"Features and labels saved to 'temporal_features.h5'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 549
        },
        "id": "pI9CfmdCLjF8",
        "outputId": "4973fe8b-e6bd-4bb6-f274-95e38fa5a341"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
            "100%|██████████| 97.8M/97.8M [00:00<00:00, 130MB/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/preprocessed_real_videos'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-a04e81251dcc>\u001b[0m in \u001b[0;36m<cell line: 113>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;31m# Extract features and save them\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_temporal_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_video_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfake_video_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_extractor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlstm_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0msave_features_to_hdf5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'temporal_features.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Features and labels saved to 'temporal_features.h5'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-a04e81251dcc>\u001b[0m in \u001b[0;36mextract_temporal_features\u001b[0;34m(real_dir, fake_dir, feature_extractor, model)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;31m# Extract features from real videos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m     \u001b[0mreal_frames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_frames_from_directory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mframes\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreal_frames\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_extractor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-a04e81251dcc>\u001b[0m in \u001b[0;36mload_frames_from_directory\u001b[0;34m(directory_path, num_frames)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_frames_from_directory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_frames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mall_frames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mvideo_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Ensure consistent ordering\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mvideo_file\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvideo_files\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mvideo_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvideo_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/preprocessed_real_videos'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J7dHoP4N4UQU",
        "outputId": "358d950e-aeeb-4915-c177-3f269cbf68d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checking first HDF5 file:\n",
            "Datasets in the file: ['data']\n",
            "Checking second HDF5 file:\n",
            "Datasets in the file: ['features', 'labels']\n"
          ]
        }
      ],
      "source": [
        "import h5py\n",
        "\n",
        "# Check keys in the HDF5 file\n",
        "def check_hdf5_keys(file_path):\n",
        "    with h5py.File(file_path, 'r') as file:\n",
        "        print(\"Datasets in the file:\", list(file.keys()))\n",
        "\n",
        "# Paths to the HDF5 files\n",
        "hdf5_file_1 = '/content/features.h5'\n",
        "hdf5_file_2 = '/content/temporal_features.h5'\n",
        "\n",
        "print(\"Checking first HDF5 file:\")\n",
        "check_hdf5_keys(hdf5_file_1)\n",
        "\n",
        "print(\"Checking second HDF5 file:\")\n",
        "check_hdf5_keys(hdf5_file_2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GSYTtaq63J4w",
        "outputId": "ed7eb7b8-abf6-47a4-ab47-c98242d03116"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Datasets in file /content/features.h5:\n",
            "data\n",
            "Features 2 shape: (10, 1)\n",
            "Labels 2 shape: (10,)\n",
            "Data 1 shape: (455706, 513)\n",
            "Combined features shape: (455716, 1)\n",
            "Combined labels shape: (20,)\n",
            "Data successfully combined and saved to: /content/drive/My Drive/new_combined_file.h5\n"
          ]
        }
      ],
      "source": [
        "import h5py\n",
        "import numpy as np\n",
        "\n",
        "# Paths to the two HDF5 files you want to fuse\n",
        "hdf5_file_1 = '/content/features.h5'\n",
        "hdf5_file_2 = '/content/temporal_features.h5'\n",
        "combined_hdf5_file = '/content/drive/My Drive/new_combined_file.h5'  # Path in Google Drive\n",
        "\n",
        "def load_dataset(file_path, dataset_name):\n",
        "    try:\n",
        "        with h5py.File(file_path, 'r') as file:\n",
        "            if dataset_name in file:\n",
        "                return file[dataset_name][:]\n",
        "            else:\n",
        "                raise KeyError(f\"Dataset '{dataset_name}' does not exist in file '{file_path}'\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading dataset '{dataset_name}' from file '{file_path}': {e}\")\n",
        "        return None\n",
        "\n",
        "# List datasets in a file to debug\n",
        "def list_datasets(file_path):\n",
        "    with h5py.File(file_path, 'r') as file:\n",
        "        print(f\"Datasets in file {file_path}:\")\n",
        "        def printname(name):\n",
        "            print(name)\n",
        "        file.visit(printname)\n",
        "\n",
        "# Load datasets from the first HDF5 file\n",
        "list_datasets(hdf5_file_1)  # This will print all available datasets in features.h5\n",
        "\n",
        "# Load datasets from the second HDF5 file\n",
        "features_2 = load_dataset(hdf5_file_2, 'features')\n",
        "labels_2 = load_dataset(hdf5_file_2, 'labels')\n",
        "\n",
        "# Explicitly check if any dataset is None\n",
        "if features_2 is None:\n",
        "    raise ValueError(\"Dataset 'features' could not be loaded from the second file.\")\n",
        "if labels_2 is None:\n",
        "    raise ValueError(\"Dataset 'labels' could not be loaded from the second file.\")\n",
        "\n",
        "# Load 'data' from the first HDF5 file\n",
        "data_1 = load_dataset(hdf5_file_1, 'data')\n",
        "\n",
        "# Check if 'data' from the first file is loaded\n",
        "if data_1 is None:\n",
        "    raise ValueError(\"Dataset 'data' could not be loaded from the first file.\")\n",
        "\n",
        "# Check shapes of the datasets\n",
        "print(\"Features 2 shape:\", features_2.shape)\n",
        "print(\"Labels 2 shape:\", labels_2.shape)\n",
        "print(\"Data 1 shape:\", data_1.shape)\n",
        "\n",
        "# Ensure feature dimensions are aligned\n",
        "feature_dim = min(features_2.shape[1], data_1.shape[1])\n",
        "\n",
        "# Truncate the features to the minimum dimension size\n",
        "features_2 = features_2[:, :feature_dim]\n",
        "data_1 = data_1[:, :feature_dim]\n",
        "\n",
        "# Combine the features\n",
        "try:\n",
        "    combined_features = np.concatenate((data_1, features_2), axis=0)\n",
        "except ValueError as e:\n",
        "    print(f\"Error combining features: {e}\")\n",
        "    raise\n",
        "\n",
        "# Combine the labels (ensure they are aligned with the combined features)\n",
        "combined_labels = np.concatenate((labels_2, labels_2))  # Adjust this based on the actual labels' alignment\n",
        "\n",
        "# Check the combined data\n",
        "print(\"Combined features shape:\", combined_features.shape)\n",
        "print(\"Combined labels shape:\", combined_labels.shape)\n",
        "\n",
        "# Create a new HDF5 file and save the combined datasets\n",
        "try:\n",
        "    with h5py.File(combined_hdf5_file, 'w') as combined_file:\n",
        "        # Save combined features\n",
        "        combined_file.create_dataset('combined_features', data=combined_features)\n",
        "\n",
        "        # Save combined labels\n",
        "        combined_file.create_dataset('combined_labels', data=combined_labels)\n",
        "\n",
        "    print(\"Data successfully combined and saved to:\", combined_hdf5_file)\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error saving combined data: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1gGKC7w4aFsV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0144e6b7-003b-4bc3-ecb7-2c7ee3ea6bd7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Datasets in file /content/drive/MyDrive/new_combined_file.h5:\n",
            "combined_features\n",
            "combined_labels\n"
          ]
        }
      ],
      "source": [
        "import h5py\n",
        "\n",
        "file_path = '/content/drive/MyDrive/new_combined_file.h5'\n",
        "\n",
        "def list_datasets(file_path):\n",
        "    with h5py.File(file_path, 'r') as file:\n",
        "        print(f\"Datasets in file {file_path}:\")\n",
        "        def printname(name):\n",
        "            print(name)\n",
        "        file.visit(printname)\n",
        "\n",
        "list_datasets(file_path)  # This will print all available datasets in the HDF5 file\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UoBwHXPT76a1",
        "outputId": "e6f3e652-2a4e-409e-db88-1addf79cbe60"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Datasets in file:\n",
            "combined_features\n",
            "combined_labels\n",
            "Features shape: (455716, 1)\n",
            "Labels shape: (20,)\n",
            "Training features shape: (16, 1)\n",
            "Training labels shape: (16,)\n",
            "Test features shape: (4, 1)\n",
            "Test labels shape: (4,)\n"
          ]
        }
      ],
      "source": [
        "import h5py\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Define file path\n",
        "file_path = '/content/drive/MyDrive/new_combined_file.h5'\n",
        "\n",
        "# Load data\n",
        "try:\n",
        "    with h5py.File(file_path, 'r') as file:\n",
        "        # List datasets to debug\n",
        "        print(\"Datasets in file:\")\n",
        "        for name in file:\n",
        "            print(name)\n",
        "\n",
        "        # Load datasets with correct names\n",
        "        features = file['combined_features'][:]  # Updated dataset name\n",
        "        labels = file['combined_labels'][:]  # Updated dataset name\n",
        "\n",
        "    # Print shapes to confirm\n",
        "    print(\"Features shape:\", features.shape)\n",
        "    print(\"Labels shape:\", labels.shape)\n",
        "\n",
        "    # Ensure labels match the number of features\n",
        "    min_length = min(features.shape[0], len(labels))\n",
        "    features = features[:min_length]\n",
        "    labels = labels[:min_length]\n",
        "\n",
        "    # Convert labels to binary if necessary\n",
        "    # Example: Assuming labels should be 0 or 1\n",
        "    labels = (labels > 0.5).astype(int)  # Adjust this based on your label encoding\n",
        "\n",
        "    # Split the data\n",
        "    X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Print shapes for training and testing data\n",
        "    print(f\"Training features shape: {X_train.shape}\")\n",
        "    print(f\"Training labels shape: {y_train.shape}\")\n",
        "    print(f\"Test features shape: {X_test.shape}\")\n",
        "    print(f\"Test labels shape: {y_test.shape}\")\n",
        "\n",
        "except KeyError as e:\n",
        "    print(f\"KeyError: {e} - Check if the dataset names are correct.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xWo0b8TLaqkL",
        "outputId": "69b6c6ee-df37-4426-8ad3-b5e141e7855a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Features shape: (455716, 1)\n",
            "Labels shape: (20,)\n",
            "Epoch 1, Loss: 0.6930401921272278\n",
            "Epoch 2, Loss: 0.6935645341873169\n",
            "Epoch 3, Loss: 0.7103979587554932\n",
            "Epoch 4, Loss: 0.6870715618133545\n",
            "Epoch 5, Loss: 0.6944384574890137\n",
            "Epoch 6, Loss: 0.6695999503135681\n",
            "Epoch 7, Loss: 0.6783062219619751\n",
            "Epoch 8, Loss: 0.6631405353546143\n",
            "Epoch 9, Loss: 0.6881166696548462\n",
            "Epoch 10, Loss: 0.6725932359695435\n",
            "Epoch 11, Loss: 0.6914709210395813\n",
            "Epoch 12, Loss: 0.6570649147033691\n",
            "Epoch 13, Loss: 0.6878570318222046\n",
            "Epoch 14, Loss: 0.6639347076416016\n",
            "Epoch 15, Loss: 0.6621781587600708\n",
            "Epoch 16, Loss: 0.6644068360328674\n",
            "Epoch 17, Loss: 0.6448448896408081\n",
            "Epoch 18, Loss: 0.6467079520225525\n",
            "Epoch 19, Loss: 0.6627320647239685\n",
            "Epoch 20, Loss: 0.6567950248718262\n",
            "Accuracy: 75.00%\n"
          ]
        }
      ],
      "source": [
        "import h5py\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load data\n",
        "file_path = '/content/drive/MyDrive/new_combined_file.h5'\n",
        "\n",
        "with h5py.File(file_path, 'r') as file:\n",
        "    features = file['/combined_features'][:]\n",
        "    labels = file['/combined_labels'][:]\n",
        "\n",
        "# Inspect shapes\n",
        "print(\"Features shape:\", features.shape)\n",
        "print(\"Labels shape:\", labels.shape)\n",
        "\n",
        "# Ensure number of labels matches number of features\n",
        "num_features = features.shape[0]\n",
        "num_labels = labels.shape[0]\n",
        "\n",
        "if num_features != num_labels:\n",
        "    min_length = min(num_features, num_labels)\n",
        "    features = features[:min_length]\n",
        "    labels = labels[:min_length]\n",
        "\n",
        "# Convert labels to binary if necessary\n",
        "# Example: Assuming labels should be 0 or 1\n",
        "labels = (labels > 0.5).astype(int)  # Adjust this based on your label encoding\n",
        "\n",
        "# Normalize features\n",
        "scaler = StandardScaler()\n",
        "features = scaler.fit_transform(features)\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define a more complex neural network\n",
        "class ImprovedNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ImprovedNN, self).__init__()\n",
        "        self.fc1 = nn.Linear(1, 512)  # Increased number of units\n",
        "        self.fc2 = nn.Linear(512, 256)\n",
        "        self.fc3 = nn.Linear(256, 128)\n",
        "        self.fc4 = nn.Linear(128, 1)\n",
        "        self.dropout = nn.Dropout(0.5)  # Dropout for regularization\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = torch.relu(self.fc3(x))\n",
        "        x = self.fc4(x)\n",
        "        x = self.sigmoid(x)\n",
        "        return x\n",
        "\n",
        "# Create datasets and loaders\n",
        "train_dataset = TensorDataset(torch.tensor(X_train, dtype=torch.float32),\n",
        "                              torch.tensor(y_train, dtype=torch.float32))\n",
        "test_dataset = TensorDataset(torch.tensor(X_test, dtype=torch.float32),\n",
        "                             torch.tensor(y_test, dtype=torch.float32))\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "# Initialize model, loss function, and optimizer\n",
        "model = ImprovedNN()\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(20):  # Increased number of epochs\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for data, targets in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(data).squeeze()\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}, Loss: {running_loss / len(train_loader)}\")\n",
        "\n",
        "# Evaluation\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for data, targets in test_loader:\n",
        "        outputs = model(data).squeeze()\n",
        "        predicted = (outputs > 0.5).float()\n",
        "        correct += (predicted == targets).sum().item()\n",
        "        total += targets.size(0)\n",
        "\n",
        "    accuracy = correct / total\n",
        "    print(f\"Accuracy: {accuracy * 100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "haVDkjSCRHVt",
        "outputId": "c5424448-54f4-4c89-ee64-ea880856ab34"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to 'simple_nn.pth'\n"
          ]
        }
      ],
      "source": [
        "# Save the model\n",
        "torch.save(model.state_dict(), 'simple_nn.pth')\n",
        "print(\"Model saved to 'simple_nn.pth'\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def save_model_to_h5(model, pth_path, h5_path):\n",
        "    # Load the state dict\n",
        "    state_dict = torch.load(pth_path)\n",
        "\n",
        "    # Create an HDF5 file\n",
        "    with h5py.File(h5_path, 'w') as f:\n",
        "        for key, value in state_dict.items():\n",
        "            # Convert tensor to numpy array and save to HDF5 dataset\n",
        "            f.create_dataset(key, data=value.cpu().numpy())\n",
        "\n",
        "# Save the model to HDF5 format\n",
        "save_model_to_h5(model, 'simple_nn.pth', 'new_modell.h5')\n",
        "print(\"Model saved to 'model.h5'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KckoH1QUkClW",
        "outputId": "cb6e940e-9208-4275-dd4f-af0ced760bac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to 'model.h5'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-68-7200d9c539dc>:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  state_dict = torch.load(pth_path)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import h5py\n",
        "\n",
        "def explore_hdf5(file_path):\n",
        "    try:\n",
        "        # Open the HDF5 file in read-only mode\n",
        "        with h5py.File(file_path, 'r') as file:\n",
        "            # Print all root level object names (aka keys)\n",
        "            print(\"Root Keys:\", list(file.keys()))\n",
        "\n",
        "            # Iterate over top-level groups and datasets\n",
        "            for key in file.keys():\n",
        "                print(f\"\\nExploring '{key}'\")\n",
        "                item = file[key]\n",
        "                if isinstance(item, h5py.Group):\n",
        "                    print(f\"Group '{key}' contains:\")\n",
        "                    for subkey in item.keys():\n",
        "                        print(f\"  Dataset '{subkey}' with shape {item[subkey].shape}\")\n",
        "                elif isinstance(item, h5py.Dataset):\n",
        "                    print(f\"Dataset '{key}' with shape {item.shape}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "\n",
        "# Replace with the actual path to your HDF5 file\n",
        "file_path = '/content/drive/MyDrive/new_combined_file.h5'\n",
        "explore_hdf5(file_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0E5F-zepUdLQ",
        "outputId": "87143dc2-35a3-4f1a-e2c6-b55e2cb04ff2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Root Keys: ['combined_features', 'combined_labels']\n",
            "\n",
            "Exploring 'combined_features'\n",
            "Dataset 'combined_features' with shape (455716, 1)\n",
            "\n",
            "Exploring 'combined_labels'\n",
            "Dataset 'combined_labels' with shape (20,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mEWEon2gM6Ov"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}